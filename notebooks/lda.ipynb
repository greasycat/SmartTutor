{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"jasper\"\n",
    "meta_path = f\"../cache/{model}_meta.tsv\"\n",
    "\n",
    "meta = pd.read_csv(meta_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rongfei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Topics:\n",
      "Topic 0: 0.060*\"language\" + 0.031*\"tasks\" + 0.030*\"training\" + 0.026*\"large\" + 0.026*\"performance\" + 0.018*\"tuning\" + 0.017*\"fine\" + 0.016*\"shot\" + 0.016*\"data\" + 0.015*\"zero\"\n",
      "Topic 1: 0.039*\"language\" + 0.030*\"tasks\" + 0.027*\"word\" + 0.024*\"large\" + 0.022*\"code\" + 0.020*\"context\" + 0.015*\"method\" + 0.015*\"performance\" + 0.014*\"knowledge\" + 0.014*\"show\"\n",
      "Topic 2: 0.081*\"text\" + 0.048*\"image\" + 0.034*\"audio\" + 0.032*\"speech\" + 0.025*\"generation\" + 0.021*\"translation\" + 0.020*\"diffusion\" + 0.014*\"synthesis\" + 0.013*\"high\" + 0.013*\"quality\"\n",
      "Topic 3: 0.040*\"optimization\" + 0.031*\"machine\" + 0.026*\"performance\" + 0.025*\"algorithm\" + 0.023*\"show\" + 0.022*\"translation\" + 0.020*\"learning\" + 0.018*\"convolutional\" + 0.017*\"process\" + 0.016*\"problems\"\n",
      "Topic 4: 0.048*\"learning\" + 0.029*\"detection\" + 0.025*\"time\" + 0.020*\"object\" + 0.019*\"real\" + 0.018*\"human\" + 0.017*\"reinforcement\" + 0.017*\"high\" + 0.016*\"approach\" + 0.016*\"using\"\n",
      "Topic 5: 0.046*\"image\" + 0.029*\"diffusion\" + 0.026*\"images\" + 0.022*\"speech\" + 0.020*\"data\" + 0.020*\"training\" + 0.017*\"high\" + 0.015*\"resolution\" + 0.014*\"large\" + 0.013*\"dataset\"\n",
      "Topic 6: 0.033*\"training\" + 0.027*\"deep\" + 0.025*\"learning\" + 0.024*\"error\" + 0.022*\"data\" + 0.017*\"generalization\" + 0.016*\"function\" + 0.016*\"parameters\" + 0.015*\"accuracy\" + 0.015*\"random\"\n",
      "Topic 7: 0.035*\"visual\" + 0.032*\"gradient\" + 0.029*\"methods\" + 0.022*\"learning\" + 0.021*\"stochastic\" + 0.017*\"self\" + 0.016*\"system\" + 0.016*\"based\" + 0.015*\"supervised\" + 0.015*\"propose\"\n",
      "Topic 8: 0.025*\"recurrent\" + 0.023*\"recognition\" + 0.022*\"deep\" + 0.019*\"based\" + 0.018*\"tasks\" + 0.018*\"data\" + 0.018*\"learning\" + 0.016*\"results\" + 0.016*\"long\" + 0.016*\"convolutional\"\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','neural','networks', 'network'])\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = simple_preprocess(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [token for token in tokens if len(token) > 3]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "meta['text'] = meta['title'] + ' ' + meta['summary']\n",
    "meta['text'] = meta['text'].apply(preprocess)\n",
    "\n",
    "dictionary = corpora.Dictionary(meta['text'])\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in meta['text']]\n",
    "num_topics = 9\n",
    "lda = LdaModel(\n",
    "        corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "print(\"Top Topics:\")\n",
    "for idx, topic in lda.print_topics(-1):\n",
    "    print(f'Topic {idx}: {topic}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el39301151405623904427042435276423\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el39301151405623904427042435276423_data = {\"mdsDat\": {\"x\": [-0.0985513599917395, -0.06783866215562119, -0.14702562065018854, 0.12607220121395463, 0.047160203261563435, -0.05931357232102796, 0.1367590418767795, 0.030879191890002173, 0.03185857687627729], \"y\": [-0.10577187507724413, -0.11474847689517277, 0.1075355549171327, 0.08510245766456276, 0.05008136510555983, 0.04318236657144164, -0.10303087057478283, 0.03728906230327339, 0.0003604159852292573], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [18.3369732838533, 6.341711823050342, 10.334610788851059, 5.069744066709449, 11.243216628248373, 11.458790050096123, 13.098849710246885, 5.8266358385196515, 18.28946781042482]}, \"tinfo\": {\"Term\": [\"text\", \"language\", \"image\", \"speech\", \"diffusion\", \"audio\", \"optimization\", \"visual\", \"learning\", \"translation\", \"gradient\", \"recurrent\", \"algorithm\", \"detection\", \"machine\", \"methods\", \"word\", \"tasks\", \"images\", \"deep\", \"large\", \"performance\", \"error\", \"generation\", \"convolutional\", \"recognition\", \"vision\", \"code\", \"algorithms\", \"context\", \"llms\", \"shot\", \"zero\", \"tuning\", \"reasoning\", \"language\", \"fine\", \"tuned\", \"benchmarks\", \"generated\", \"improving\", \"parameter\", \"additional\", \"downstream\", \"strong\", \"scaling\", \"question\", \"extensive\", \"evaluate\", \"remarkable\", \"domain\", \"generalize\", \"improvement\", \"improvements\", \"specifically\", \"capabilities\", \"size\", \"range\", \"outperforms\", \"human\", \"find\", \"natural\", \"tasks\", \"large\", \"performance\", \"training\", \"understanding\", \"wide\", \"datasets\", \"task\", \"parameters\", \"data\", \"trained\", \"without\", \"state\", \"efficient\", \"using\", \"learning\", \"show\", \"scale\", \"word\", \"context\", \"decision\", \"knowledge\", \"sampling\", \"code\", \"making\", \"open\", \"improved\", \"question\", \"world\", \"like\", \"solve\", \"class\", \"capabilities\", \"performing\", \"good\", \"need\", \"beyond\", \"given\", \"similar\", \"arbitrary\", \"rate\", \"example\", \"still\", \"words\", \"superior\", \"examples\", \"particular\", \"level\", \"available\", \"language\", \"reasoning\", \"tasks\", \"problem\", \"method\", \"vision\", \"large\", \"scale\", \"show\", \"performance\", \"real\", \"also\", \"using\", \"paper\", \"many\", \"audio\", \"text\", \"synthesis\", \"fidelity\", \"generation\", \"translation\", \"decoder\", \"samples\", \"latent\", \"encoder\", \"speech\", \"diffusion\", \"generates\", \"image\", \"words\", \"quality\", \"pretrained\", \"modeling\", \"generate\", \"ability\", \"generative\", \"space\", \"various\", \"need\", \"introduce\", \"make\", \"multiple\", \"given\", \"attention\", \"transfer\", \"representation\", \"high\", \"scale\", \"representations\", \"large\", \"trained\", \"training\", \"language\", \"based\", \"task\", \"data\", \"approach\", \"optimization\", \"machine\", \"properties\", \"order\", \"process\", \"application\", \"encoder\", \"setting\", \"decoder\", \"translation\", \"furthermore\", \"fixed\", \"algorithm\", \"problems\", \"semantic\", \"proposed\", \"good\", \"apply\", \"free\", \"second\", \"finally\", \"source\", \"cases\", \"result\", \"framework\", \"algorithms\", \"prediction\", \"rate\", \"generates\", \"learned\", \"convolutional\", \"words\", \"novel\", \"show\", \"performance\", \"approach\", \"methods\", \"problem\", \"learning\", \"task\", \"based\", \"paper\", \"state\", \"well\", \"also\", \"high\", \"tasks\", \"detection\", \"reinforcement\", \"control\", \"object\", \"objects\", \"domains\", \"speed\", \"real\", \"faster\", \"time\", \"challenge\", \"single\", \"learns\", \"arbitrary\", \"inputs\", \"dimensional\", \"allows\", \"complex\", \"world\", \"challenging\", \"represent\", \"algorithm\", \"addition\", \"thus\", \"achieving\", \"functions\", \"human\", \"requires\", \"framework\", \"developed\", \"learning\", \"quality\", \"approach\", \"high\", \"algorithms\", \"representations\", \"using\", \"space\", \"deep\", \"features\", \"work\", \"however\", \"demonstrate\", \"method\", \"methods\", \"training\", \"architecture\", \"images\", \"resolution\", \"diffusion\", \"content\", \"images\", \"conditional\", \"imagenet\", \"achieving\", \"labeled\", \"image\", \"learned\", \"prior\", \"consists\", \"able\", \"speech\", \"powerful\", \"fidelity\", \"generative\", \"similar\", \"layers\", \"dataset\", \"self\", \"latent\", \"steps\", \"stable\", \"control\", \"diverse\", \"requires\", \"produce\", \"supervised\", \"free\", \"high\", \"synthesis\", \"attention\", \"multi\", \"transformer\", \"data\", \"structure\", \"convolutional\", \"training\", \"recognition\", \"state\", \"trained\", \"large\", \"show\", \"also\", \"vision\", \"results\", \"tasks\", \"using\", \"representations\", \"deep\", \"performance\", \"scale\", \"method\", \"learning\", \"random\", \"distribution\", \"error\", \"descent\", \"regression\", \"linear\", \"theory\", \"layer\", \"complexity\", \"function\", \"probability\", \"test\", \"analysis\", \"technique\", \"generalization\", \"sample\", \"weights\", \"computational\", \"increasing\", \"parameters\", \"better\", \"empirical\", \"number\", \"accuracy\", \"much\", \"higher\", \"reducing\", \"cost\", \"layers\", \"structure\", \"deep\", \"training\", \"method\", \"data\", \"classification\", \"learning\", \"problem\", \"using\", \"also\", \"performance\", \"show\", \"stochastic\", \"self\", \"gradient\", \"terms\", \"visual\", \"described\", \"supervised\", \"prediction\", \"objective\", \"specifically\", \"methods\", \"since\", \"semantic\", \"system\", \"order\", \"units\", \"processing\", \"inference\", \"information\", \"propose\", \"latent\", \"require\", \"systems\", \"optimization\", \"outperform\", \"much\", \"proposed\", \"descent\", \"multiple\", \"many\", \"transformer\", \"natural\", \"features\", \"based\", \"efficient\", \"learning\", \"results\", \"method\", \"large\", \"recognition\", \"trained\", \"show\", \"language\", \"work\", \"used\", \"tasks\", \"term\", \"long\", \"recurrent\", \"sequences\", \"short\", \"computer\", \"recognition\", \"feature\", \"spatial\", \"artificial\", \"sequence\", \"vision\", \"achieved\", \"found\", \"memory\", \"temporal\", \"convolutional\", \"uses\", \"still\", \"outperform\", \"demonstrated\", \"possible\", \"system\", \"classification\", \"transformers\", \"systems\", \"difficult\", \"limited\", \"efficiency\", \"algorithms\", \"based\", \"deep\", \"results\", \"visual\", \"used\", \"paper\", \"data\", \"tasks\", \"state\", \"trained\", \"learning\", \"show\", \"time\", \"performance\", \"image\", \"large\", \"using\"], \"Freq\": [164.0, 258.0, 219.0, 119.0, 86.0, 61.0, 58.0, 80.0, 284.0, 57.0, 61.0, 90.0, 75.0, 70.0, 52.0, 101.0, 42.0, 228.0, 85.0, 173.0, 196.0, 194.0, 63.0, 67.0, 96.0, 107.0, 79.0, 61.0, 64.0, 32.0, 36.12802956346168, 47.55720814359834, 44.853230612890954, 51.700579161131714, 29.707164245296166, 174.43458810699622, 49.16514698442793, 13.992038595450675, 24.718081355412778, 18.845502054956018, 9.88058803635446, 27.206336942207773, 11.568568164827361, 11.400721466269285, 12.447136571459753, 11.903144529575885, 12.055667748182188, 9.681978048699866, 13.05146196694907, 7.9622380096818635, 10.22228157079246, 9.768524927409937, 11.884700570044146, 8.947455115627873, 8.067369667473063, 19.21598400336068, 22.43657471805453, 19.580459011566713, 15.91406081501027, 42.21073204023913, 22.37073103425555, 24.547397176948873, 89.7409382053138, 77.35036347257147, 75.85392650335187, 86.73950896903338, 20.274193256028347, 17.671909209186467, 25.765552947367514, 30.99249706336309, 24.44714998468725, 47.52316110587908, 35.33405765076592, 25.469176096326066, 33.513518025891585, 20.75551175469371, 30.664895007891616, 35.50347105184692, 26.405143095520092, 20.304815725575473, 27.033069121874398, 20.405824242578614, 11.879817037592606, 14.568110166385296, 11.520785317617339, 22.51845788261215, 10.483452177687756, 12.146156977550666, 8.04117990116909, 7.300510052770498, 11.90920635672024, 7.898142595987099, 5.852569191708696, 10.932897297277139, 12.10114931841079, 4.2197576650031, 4.4436534766837426, 4.238989322469967, 5.558629886991721, 8.035003523397318, 5.569169631446232, 4.548336162899186, 3.189704331603082, 5.661446390497819, 5.377276547558806, 5.95771301233038, 4.068602982635307, 5.5617627776822935, 5.259670334335766, 9.008336854284218, 8.859658651896071, 39.40402159374319, 7.302765846998586, 30.601539843858664, 9.916280385275334, 15.460849437239164, 12.320746228116505, 23.771776026428757, 11.62635686392808, 14.474575169168103, 14.696885243145648, 8.451839852830995, 10.227835965401392, 11.946212863366497, 9.836860806342283, 7.733195759964849, 55.751732785401, 134.02787157418484, 22.95874229577477, 11.682015102207043, 41.142369532707406, 34.85132482385302, 17.756567993318807, 13.527573591123115, 17.785711461797295, 15.471186669965766, 52.70705851812891, 32.142189217922365, 6.037555731001516, 79.73488571155886, 9.84695964143784, 21.002375594668944, 6.150879854365241, 12.551041187463696, 10.500941650584444, 8.985173031156332, 13.071469031005892, 15.422234906014555, 9.099240195643976, 4.320888422060805, 12.660292770673518, 5.7028425431068275, 11.511877855137294, 7.518928984471554, 10.42018021176892, 4.59503685704537, 11.202995123155675, 21.174825547651736, 15.821190478635996, 12.282879256147277, 18.68068110778206, 14.79238754736766, 19.774350225587582, 18.833808924293745, 13.579788908246046, 11.889861878018744, 13.357491554539353, 11.361845659902452, 32.116061522584026, 24.962010416534987, 8.93675661253302, 12.620689650761314, 13.450400252671304, 6.057743249673495, 11.152143233684912, 6.230562008346261, 10.775795421928935, 17.522263292328496, 5.36820084134272, 5.851871426948098, 20.368878874487464, 12.70309886754551, 7.828084138601486, 9.484632929289203, 4.121745074206321, 4.4943063864089465, 5.94888759427433, 4.972754265894842, 5.779271523580623, 5.647677686331533, 4.0409815891473295, 4.099869443864028, 7.8172106480303425, 11.943803765773676, 4.869167585187092, 2.7906488542336008, 3.006726846826024, 4.219577900635506, 14.219797702148758, 4.971843564979021, 8.860170464801662, 18.329828175809638, 21.248946234017946, 12.561074664747514, 12.17827633696324, 8.1054066737411, 16.55105211243456, 9.724484692174864, 10.59664576841384, 9.207739224816272, 8.601004770556257, 7.069554161019154, 7.758129067179134, 7.329458647746457, 7.0815696953657765, 52.32506793880153, 30.508645925336356, 19.94676695079479, 35.75703377875715, 11.301922267341766, 14.722930470623753, 12.196670078105733, 34.31622271652061, 16.92854475627729, 44.37690997422631, 12.165412334160948, 20.432974237922476, 10.115556198289545, 8.085281096496232, 10.970890837827396, 16.384977519373642, 8.934570075077882, 16.399084339681266, 13.577650202881433, 10.75925933518167, 6.415528270148381, 26.278558603840985, 6.461739994425767, 6.0322619795960675, 7.024001062368052, 12.512749612861171, 31.430886602455026, 6.341023653456269, 12.922551491453405, 5.019551619337201, 85.63890722165038, 19.214320151532217, 29.519646869252746, 30.031606820064425, 17.960226328872977, 21.629180877781835, 29.400619008726927, 14.976990049793747, 22.97072697559471, 15.072757924286618, 15.492527176565158, 13.759670730552642, 14.449902181805344, 15.319416219614553, 15.164539850380327, 16.864901390146688, 14.169704524937039, 14.263805608952405, 26.64221225441417, 52.7020342023568, 14.288515581489078, 47.16428615893724, 12.330082532489783, 20.796201647407482, 9.408808286447599, 7.883084338134002, 83.36044940620975, 8.735125954516963, 11.731730107758992, 6.112218506938888, 8.890264752563704, 41.04886485560532, 11.933010599527352, 6.436430435414967, 15.572431377915862, 8.361147824481872, 17.854298399803337, 23.197139235702515, 10.151196425047674, 11.555674932206344, 5.873899252052012, 5.236115957048002, 8.70430786031524, 10.265588205006914, 5.8828589197954875, 6.445668551743183, 11.008080921243392, 7.52761644974279, 31.419356095331217, 9.816110973059418, 12.969868956854546, 11.693360317894186, 13.327799095937076, 36.26433086171558, 14.228113919330033, 19.821706420590463, 35.928390083692975, 19.52455119230423, 22.36213357135751, 21.023305163345974, 26.079499548080705, 21.235852832656235, 17.50039237416073, 15.059574146733462, 17.543646704847916, 21.24087255920373, 17.715305368548076, 14.479205674565776, 17.129949478370975, 17.019858985099365, 14.530780304032398, 14.816773782637819, 14.440981273122317, 31.065454193540756, 26.016783528441536, 49.81729852419952, 25.563467006868994, 26.161217813795925, 24.912754629383738, 18.245095831859942, 29.701620858068683, 23.28589398867313, 34.424857581257015, 12.51683526258478, 24.647289762320344, 23.323460431916548, 15.99008581117769, 35.88501931688281, 15.330653415872398, 14.264957800679952, 19.107609783506746, 9.492133022521047, 33.633174822063225, 26.099005560044215, 10.6556946067695, 23.636144798062478, 31.260964535123236, 13.818314444773073, 8.801815124954832, 7.181806482196883, 8.718255738858131, 20.72980717795113, 22.302479691874158, 56.16696435801464, 68.61812735086026, 29.714012769259657, 45.271918285740895, 24.150316780600647, 52.350014676372645, 17.493525932169987, 23.72353352769584, 20.10668939988032, 21.82167742532273, 18.128263921236826, 19.534603995393713, 15.691422098790648, 29.92923821641083, 10.482960450949502, 32.2838388401138, 6.808221115695187, 14.03451585761165, 9.11207341252065, 5.400081284463386, 5.699212979156171, 26.93619023032247, 4.095662864109481, 7.601490130390591, 15.30057732082296, 6.672986059081226, 6.749766119468204, 7.650697642191162, 7.559131550253565, 11.874763492022103, 13.758660673508768, 6.967794479147357, 6.030860022316017, 9.082150299519729, 10.550931839284674, 3.5099205426976257, 5.562350209645275, 6.721616846046601, 5.605006663404077, 8.869671727478812, 9.121519767579887, 8.472149219522795, 8.836126574995681, 9.722800802654861, 14.75891770146924, 8.562121752433006, 19.99955142977209, 11.665920793942202, 10.537449275033993, 12.865173829692909, 9.390923761284876, 8.909663747085208, 8.775473625948509, 8.940553544292646, 7.923561984907325, 7.817828522018185, 7.9449362546615, 27.973275975204633, 46.08019211778329, 71.73221417469293, 24.060739185440358, 20.92084318209643, 18.407923519084793, 66.3407175852479, 23.356427249903472, 14.745830403339756, 15.95813248935249, 25.440419882959635, 43.30442941012379, 10.215072963217573, 9.015691355234301, 23.900536657099426, 17.48169311152208, 45.50123365315675, 10.451163113855063, 11.514222211550594, 8.475623244495834, 7.3056713126795545, 9.45685694533143, 27.443369458782374, 33.619520802927845, 20.208071393599177, 19.894961840528946, 7.469172830841894, 9.362622678489204, 8.036214356300727, 25.124172829080237, 55.41444158393766, 65.08419736499381, 46.58762587754471, 30.583375383218666, 25.844093559732645, 30.77154672283858, 51.76012708179044, 53.22458543958244, 35.57653693264815, 32.88291377904466, 51.670398901209836, 32.88408627069653, 24.422032174380146, 30.7583833327655, 31.856975441355207, 30.5653564663743, 26.94308464117611], \"Total\": [164.0, 258.0, 219.0, 119.0, 86.0, 61.0, 58.0, 80.0, 284.0, 57.0, 61.0, 90.0, 75.0, 70.0, 52.0, 101.0, 42.0, 228.0, 85.0, 173.0, 196.0, 194.0, 63.0, 67.0, 96.0, 107.0, 79.0, 61.0, 64.0, 32.0, 43.16293159991317, 58.17176106886566, 55.169783221893795, 67.3744431213209, 39.788880091233395, 258.4465921736625, 75.91166668998589, 21.888628413611613, 38.90250886041303, 30.891850594824756, 16.88469019851894, 48.478871962822936, 20.951392708112255, 20.695724337163416, 23.785093560428148, 22.87126480475609, 23.381989328946627, 18.944486785731662, 25.785742775463177, 15.863806273246599, 20.892983401393984, 20.07420935703542, 25.929283930591765, 19.626532079956494, 17.72807532367007, 42.85421717746398, 50.917669126322195, 44.58571444971772, 36.4621575561609, 97.31067378911176, 51.736948626224375, 57.04007358502748, 228.7495644970228, 196.64598062399125, 194.01051563059556, 252.31508195480538, 47.49296375579543, 41.8461824767715, 70.35755711667161, 94.84768340921384, 70.55810450651259, 206.6794506242287, 128.30084880760614, 81.01954805691369, 138.53404205045075, 59.73574089489225, 160.28706686520832, 284.6856257964388, 148.56865316310518, 88.12727057331875, 42.97561468512242, 32.91617490928794, 22.886431117650076, 31.68579987692329, 27.431215267064513, 61.684753029606185, 28.893439264964034, 34.828531585783864, 24.026919728507913, 23.381989328946627, 38.22459714553331, 26.629681124443103, 20.14641142362658, 38.38436811891177, 42.85421717746398, 15.446302939632933, 17.45438981445456, 18.105998802025816, 24.264234527607627, 35.40438802209946, 25.219571328333895, 21.278649463011504, 15.281486172104207, 27.25173808653042, 26.18683587930751, 29.548112602670773, 20.57078300468059, 28.44052124404459, 27.416312282572576, 48.37053118434469, 48.61425509345835, 258.4465921736625, 39.788880091233395, 228.7495644970228, 58.60261826482086, 105.52041378849428, 79.8092803264664, 196.64598062399125, 88.12727057331875, 148.56865316310518, 194.01051563059556, 65.1325544109987, 108.46475145581283, 160.28706686520832, 102.8877665942942, 54.79315019479585, 61.23462157686517, 164.30831602277655, 36.06379265182731, 18.96991723475047, 67.01010998630133, 57.063055016565826, 33.477817457789925, 27.946826170661957, 37.04258204413244, 33.571360782064154, 119.19350357613614, 86.95196619787454, 16.476274540380885, 219.79401731286697, 29.548112602670773, 64.16869433463314, 19.472126710648354, 39.762369747578376, 33.917024960579624, 29.960799453136705, 46.53638967925903, 58.365236340310865, 36.59950327943093, 18.105998802025816, 56.67544269024219, 26.129291423763267, 53.27432427314842, 35.40438802209946, 49.64278164880232, 22.697712611042206, 55.54450222659665, 116.61592921156817, 88.12727057331875, 82.37995509402379, 196.64598062399125, 128.30084880760614, 252.31508195480538, 258.4465921736625, 146.07389861989077, 94.84768340921384, 206.6794506242287, 104.32736488103869, 58.258057879422886, 52.7761834678715, 19.732383168945386, 28.97233263434101, 31.15343541091204, 16.654270981255433, 33.571360782064154, 18.76960421993331, 33.477817457789925, 57.063055016565826, 17.66120429221629, 20.497132799467057, 75.97773911112556, 50.815681866812156, 31.61345240070386, 39.46412795157133, 17.45438981445456, 19.546896916610148, 27.36226829086218, 23.19379532106555, 27.56463401081498, 28.38324546963877, 20.787378326881225, 21.561006855075583, 42.117380225402755, 64.67932399895017, 26.399003477933853, 15.281486172104207, 16.476274540380885, 23.34934410578379, 96.51806273691878, 29.548112602670773, 58.57663108787831, 148.56865316310518, 194.01051563059556, 104.32736488103869, 101.63397929166945, 58.60261826482086, 284.6856257964388, 94.84768340921384, 146.07389861989077, 102.8877665942942, 138.53404205045075, 63.382393470094, 108.46475145581283, 116.61592921156817, 228.7495644970228, 70.87949840939511, 44.674339245182495, 29.466666514625864, 59.866585133192345, 19.521513330340838, 26.7486137471155, 22.533203937215575, 65.1325544109987, 36.426610060280915, 95.84375101991557, 29.421344728518225, 51.01997575085728, 26.19241183330305, 21.278649463011504, 29.4173247635112, 44.503292939717724, 24.517467998988494, 46.04078329221945, 38.22459714553331, 30.355065260629523, 18.287486260152, 75.97773911112556, 18.726414148825942, 17.90997892898428, 21.599283704085533, 38.478622493361435, 97.31067378911176, 20.369743515884917, 42.117380225402755, 16.666520374431283, 284.6856257964388, 64.16869433463314, 104.32736488103869, 116.61592921156817, 64.67932399895017, 82.37995509402379, 160.28706686520832, 58.365236340310865, 173.99615110995222, 65.65152844736295, 71.47217868872269, 55.90548191988857, 75.80037727289705, 105.52041378849428, 101.63397929166945, 252.31508195480538, 73.14500063826638, 85.11461785058883, 42.459058487249756, 86.95196619787454, 25.187387769211064, 85.11461785058883, 24.963929966210998, 43.220381230625236, 21.599283704085533, 18.609593245556024, 219.79401731286697, 23.34934410578379, 33.144144347078, 17.33205634764945, 25.318356764486918, 119.19350357613614, 34.96508851262784, 18.96991723475047, 46.53638967925903, 25.219571328333895, 54.34007769597001, 71.75132604156516, 31.671367817217668, 37.04258204413244, 19.427083391787317, 17.498140968693757, 29.466666514625864, 35.361539969645015, 20.369743515884917, 22.332200305281347, 39.95379875877224, 27.36226829086218, 116.61592921156817, 36.06379265182731, 49.64278164880232, 44.882093049004986, 52.557426131933155, 206.6794506242287, 59.31255346240145, 96.51806273691878, 252.31508195480538, 107.71135029139703, 138.53404205045075, 128.30084880760614, 196.64598062399125, 148.56865316310518, 108.46475145581283, 79.8092803264664, 125.44271237459061, 228.7495644970228, 160.28706686520832, 82.37995509402379, 173.99615110995222, 194.01051563059556, 88.12727057331875, 105.52041378849428, 284.6856257964388, 37.5046307051123, 32.44344261419323, 63.4589055866095, 33.20251045613354, 34.3305970986128, 35.199757571723424, 27.098871107197247, 44.23108784380226, 35.091786041714506, 56.17283582749286, 20.872512543608543, 41.413408387451824, 40.1813565401546, 27.798325496777586, 64.51045975527217, 27.706192273996166, 26.773884712529405, 36.847395409446406, 19.68893430470655, 70.55810450651259, 55.02802281430558, 22.941973321590638, 51.2843356631045, 69.83580811705356, 31.493322629247324, 20.665797626604437, 17.045710965197227, 20.923070005094356, 54.34007769597001, 59.31255346240145, 173.99615110995222, 252.31508195480538, 105.52041378849428, 206.6794506242287, 80.76297800271747, 284.6856257964388, 58.60261826482086, 160.28706686520832, 108.46475145581283, 194.01051563059556, 148.56865316310518, 25.89055617952841, 31.671367817217668, 61.5736017040923, 23.135584657712126, 80.72055125240018, 17.62458415036143, 39.95379875877224, 26.399003477933853, 16.471884798388206, 17.72807532367007, 101.63397929166945, 16.429979536251253, 31.61345240070386, 65.64318685325442, 28.97233263434101, 29.94380893337878, 35.84922079347176, 38.833911239992965, 61.27014772121483, 72.62218464928016, 37.04258204413244, 32.093633497618086, 49.14954110392092, 58.258057879422886, 19.405640587170588, 31.493322629247324, 39.46412795157133, 33.20251045613354, 53.27432427314842, 54.79315019479585, 52.557426131933155, 57.04007358502748, 65.65152844736295, 146.07389861989077, 59.73574089489225, 284.6856257964388, 125.44271237459061, 105.52041378849428, 196.64598062399125, 107.71135029139703, 128.30084880760614, 148.56865316310518, 258.4465921736625, 71.47217868872269, 75.84416402712169, 228.7495644970228, 32.97946047802881, 54.35767124310457, 90.08514170630556, 31.842680467802275, 29.050766110325466, 28.004081635416096, 107.71135029139703, 38.918454591415106, 25.044920203009905, 28.470279657918798, 46.48997459350282, 79.8092803264664, 19.402598970257138, 17.461960614763463, 50.17848755032243, 36.70816081367367, 96.51806273691878, 22.552565056287605, 26.18683587930751, 19.405640587170588, 16.804176421243895, 22.460546304768926, 65.64318685325442, 80.76297800271747, 48.64277841760962, 49.14954110392092, 18.624023722675386, 23.37770622009579, 20.65980276127768, 64.67932399895017, 146.07389861989077, 173.99615110995222, 125.44271237459061, 80.72055125240018, 75.84416402712169, 102.8877665942942, 206.6794506242287, 228.7495644970228, 138.53404205045075, 128.30084880760614, 284.6856257964388, 148.56865316310518, 95.84375101991557, 194.01051563059556, 219.79401731286697, 196.64598062399125, 160.28706686520832], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.3929, -4.118, -4.1766, -4.0345, -4.5886, -2.8184, -4.0848, -5.3415, -4.7724, -5.0437, -5.6894, -4.6765, -5.5317, -5.5463, -5.4585, -5.5032, -5.4904, -5.7097, -5.4111, -5.9052, -5.6554, -5.7008, -5.5047, -5.7886, -5.8921, -5.0242, -4.8693, -5.0054, -5.2128, -4.2373, -4.8722, -4.7794, -3.483, -3.6316, -3.6512, -3.5171, -4.9706, -5.108, -4.7309, -4.5462, -4.7834, -4.1187, -4.4151, -4.7425, -4.468, -4.9471, -4.5568, -4.4103, -4.7064, -4.9691, -3.6211, -3.9024, -4.4433, -4.2394, -4.474, -3.8039, -4.5684, -4.4212, -4.8336, -4.9302, -4.4409, -4.8516, -5.1513, -4.5264, -4.4249, -5.4784, -5.4267, -5.4739, -5.2028, -4.8344, -5.2009, -5.4034, -5.7583, -5.1845, -5.236, -5.1335, -5.5149, -5.2023, -5.2581, -4.72, -4.7367, -3.2443, -4.9299, -3.4971, -4.624, -4.1799, -4.4069, -3.7497, -4.4649, -4.2458, -4.2306, -4.7838, -4.5931, -4.4378, -4.6321, -4.8727, -3.3856, -2.5085, -4.2728, -4.9485, -3.6895, -3.8554, -4.5298, -4.8018, -4.5281, -4.6676, -3.4418, -3.9364, -5.6085, -3.0278, -5.1194, -4.3619, -5.5899, -4.8767, -5.0551, -5.211, -4.8361, -4.6707, -5.1983, -5.9431, -4.8681, -5.6656, -4.9632, -5.3891, -5.0628, -5.8816, -4.9904, -4.3537, -4.6452, -4.8983, -4.479, -4.7124, -4.4222, -4.4709, -4.798, -4.9309, -4.8145, -4.9763, -3.225, -3.477, -4.5042, -4.159, -4.0953, -4.893, -4.2827, -4.8649, -4.317, -3.8309, -5.0138, -4.9276, -3.6803, -4.1525, -4.6366, -4.4447, -5.2781, -5.1915, -4.9111, -5.0904, -4.9401, -4.9631, -5.2978, -5.2834, -4.638, -4.2141, -5.1114, -5.6681, -5.5935, -5.2546, -4.0397, -5.0905, -4.5128, -3.7858, -3.638, -4.1637, -4.1947, -4.6018, -3.8879, -4.4197, -4.3338, -4.4743, -4.5425, -4.7385, -4.6456, -4.7024, -4.7368, -3.5333, -4.0728, -4.4977, -3.9141, -5.0658, -4.8014, -4.9896, -3.9552, -4.6618, -3.6981, -4.9922, -4.4737, -5.1767, -5.4008, -5.0956, -4.6944, -5.3009, -4.6936, -4.8824, -5.115, -5.6321, -4.2221, -5.6249, -5.6937, -5.5415, -4.9641, -4.043, -5.6438, -4.9318, -5.8775, -3.0407, -4.5351, -4.1057, -4.0886, -4.6026, -4.4168, -4.1098, -4.7843, -4.3566, -4.7779, -4.7504, -4.8691, -4.8201, -4.7617, -4.7718, -4.6656, -4.8397, -4.8331, -4.2273, -3.5451, -4.8503, -3.6562, -4.9978, -4.475, -5.2682, -5.4451, -3.0866, -5.3424, -5.0475, -5.6995, -5.3248, -3.795, -5.0305, -5.6478, -4.7643, -5.3862, -4.6276, -4.3658, -5.1922, -5.0626, -5.7393, -5.8542, -5.346, -5.181, -5.7378, -5.6464, -5.1112, -5.4912, -4.0624, -5.2258, -4.9472, -5.0508, -4.9199, -3.919, -4.8546, -4.523, -3.9283, -4.5381, -4.4024, -4.4642, -4.2486, -4.4541, -4.6476, -4.7978, -4.6451, -4.4539, -4.6354, -4.8371, -4.669, -4.6754, -4.8335, -4.814, -4.8397, -4.2075, -4.3848, -3.7352, -4.4024, -4.3793, -4.4282, -4.7397, -4.2524, -4.4957, -4.1048, -5.1165, -4.4389, -4.4941, -4.8716, -4.0632, -4.9137, -4.9858, -4.6935, -5.3931, -4.1281, -4.3817, -5.2775, -4.4808, -4.2012, -5.0176, -5.4686, -5.672, -5.4781, -4.612, -4.5389, -3.6152, -3.415, -4.2519, -3.8309, -4.4593, -3.6856, -4.7817, -4.4771, -4.6425, -4.5607, -4.7461, -3.8613, -4.0804, -3.4346, -4.4837, -3.3589, -4.9153, -4.192, -4.6239, -5.1471, -5.0932, -3.54, -5.4236, -4.8051, -4.1056, -4.9354, -4.924, -4.7987, -4.8107, -4.3591, -4.2118, -4.8922, -5.0366, -4.6272, -4.4773, -5.5779, -5.1175, -4.9282, -5.1098, -4.6508, -4.6228, -4.6967, -4.6546, -4.559, -4.1416, -4.6861, -3.8378, -4.3768, -4.4785, -4.279, -4.5937, -4.6463, -4.6615, -4.6429, -4.7636, -4.7771, -4.7609, -4.6461, -4.147, -3.7044, -4.7968, -4.9366, -5.0646, -3.7826, -4.8265, -5.2864, -5.2074, -4.741, -4.2091, -5.6535, -5.7784, -4.8035, -5.1162, -4.1596, -5.6307, -5.5338, -5.8402, -5.9887, -5.7306, -4.6652, -4.4623, -4.9713, -4.9869, -5.9666, -5.7406, -5.8934, -4.7535, -3.9625, -3.8017, -4.136, -4.5569, -4.7253, -4.5508, -4.0307, -4.0028, -4.4057, -4.4844, -4.0325, -4.4844, -4.7819, -4.5512, -4.5161, -4.5575, -4.6836], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5183, 1.4948, 1.4892, 1.4315, 1.4041, 1.3031, 1.2619, 1.2488, 1.2427, 1.202, 1.1604, 1.1186, 1.1023, 1.1, 1.0487, 1.0432, 1.0338, 1.025, 1.0153, 1.0069, 0.9814, 0.976, 0.9161, 0.9107, 0.9089, 0.8942, 0.8767, 0.8734, 0.8672, 0.861, 0.8578, 0.8531, 0.7605, 0.7632, 0.7571, 0.6285, 0.845, 0.8342, 0.6917, 0.5777, 0.6363, 0.2263, 0.4067, 0.539, 0.2771, 0.6391, 0.0424, -0.3855, -0.0312, 0.2283, 2.2944, 2.2799, 2.1023, 1.981, 1.8905, 1.7503, 1.7442, 1.7046, 1.6634, 1.594, 1.5919, 1.5426, 1.5219, 1.5021, 1.4935, 1.4604, 1.3899, 1.3061, 1.2844, 1.275, 1.2476, 1.2151, 1.1913, 1.1866, 1.1749, 1.1567, 1.1374, 1.1261, 1.107, 1.0773, 1.0556, 0.8772, 1.0627, 0.7464, 0.9814, 0.8374, 0.8897, 0.6451, 0.7325, 0.4294, 0.1777, 0.716, 0.3967, 0.1615, 0.4105, 0.8, 2.1759, 2.066, 1.8181, 1.7849, 1.7819, 1.7766, 1.6355, 1.5441, 1.536, 1.495, 1.4537, 1.2745, 1.2657, 1.2557, 1.1708, 1.1528, 1.1173, 1.1166, 1.0972, 1.0654, 0.9999, 0.9388, 0.8778, 0.8369, 0.7708, 0.7476, 0.7376, 0.7203, 0.7086, 0.6724, 0.6687, 0.5636, 0.5522, 0.3665, -0.0842, 0.1094, -0.2766, -0.3494, -0.1059, 0.1931, -0.4694, 0.0524, 2.3864, 2.2332, 2.1898, 2.1509, 2.142, 1.9706, 1.8798, 1.8791, 1.8483, 1.8012, 1.791, 1.7284, 1.6654, 1.5955, 1.586, 1.5562, 1.5386, 1.5119, 1.4559, 1.442, 1.4196, 1.3673, 1.344, 1.3219, 1.2977, 1.2927, 1.2915, 1.2815, 1.2808, 1.271, 1.0668, 1.1997, 1.0931, 0.8894, 0.7703, 0.8649, 0.8602, 1.0036, 0.1369, 0.7043, 0.3583, 0.5683, 0.2026, 0.7885, 0.3442, 0.2149, -0.4933, 1.8819, 1.804, 1.7952, 1.67, 1.6389, 1.5883, 1.5716, 1.5446, 1.4191, 1.4154, 1.3023, 1.2703, 1.234, 1.2177, 1.1991, 1.1862, 1.1759, 1.1531, 1.1504, 1.1482, 1.1379, 1.1237, 1.1214, 1.0972, 1.0621, 1.0621, 1.0553, 1.0184, 1.0039, 0.9853, 0.9842, 0.9795, 0.9229, 0.8288, 0.9041, 0.8481, 0.4895, 0.8252, 0.1606, 0.7139, 0.6565, 0.7835, 0.528, 0.2556, 0.283, -0.52, 0.5441, 0.3991, 1.7004, 1.6657, 1.5995, 1.5761, 1.461, 1.4349, 1.3354, 1.3075, 1.1969, 1.1832, 1.1278, 1.1241, 1.1198, 1.1004, 1.0914, 1.0855, 1.0717, 1.0624, 1.0534, 1.0372, 1.0286, 1.0015, 0.9703, 0.9599, 0.947, 0.9296, 0.9244, 0.9238, 0.8773, 0.8758, 0.855, 0.8651, 0.8242, 0.8214, 0.7944, 0.4261, 0.7388, 0.5835, 0.2173, 0.4586, 0.3427, 0.3577, 0.1462, 0.2211, 0.3422, 0.4988, 0.1993, -0.2103, -0.0361, 0.4278, -0.1518, -0.2671, 0.3639, 0.2033, -0.8149, 1.8443, 1.8119, 1.7906, 1.7712, 1.7609, 1.687, 1.637, 1.6344, 1.6225, 1.543, 1.5213, 1.5137, 1.4887, 1.4796, 1.4461, 1.4408, 1.403, 1.3759, 1.3031, 1.2917, 1.2867, 1.2658, 1.258, 1.2289, 1.2089, 1.1791, 1.1683, 1.1572, 1.069, 1.0545, 0.9019, 0.7305, 0.7654, 0.5142, 0.8254, 0.3392, 0.8237, 0.1221, 0.3473, -0.1524, -0.0709, 2.561, 2.1404, 2.1213, 2.0511, 1.9263, 1.8916, 1.7965, 1.779, 1.7275, 1.7079, 1.5148, 1.4536, 1.4175, 1.3864, 1.3745, 1.3529, 1.2982, 1.2062, 1.2019, 1.1791, 1.172, 1.171, 1.1542, 1.1341, 1.1328, 1.109, 1.0727, 1.0638, 1.0499, 1.0498, 1.0176, 0.9778, 0.9328, 0.5505, 0.9001, 0.1871, 0.4676, 0.5388, 0.1158, 0.403, 0.1755, 0.0136, -0.5214, 0.6433, 0.5705, -0.5174, 1.5342, 1.5336, 1.471, 1.4186, 1.3705, 1.2793, 1.2142, 1.1882, 1.1691, 1.12, 1.0959, 1.0875, 1.0573, 1.0378, 0.9572, 0.957, 0.9469, 0.9297, 0.8772, 0.8705, 0.8659, 0.8338, 0.8267, 0.8224, 0.8204, 0.7944, 0.7852, 0.7838, 0.7546, 0.7532, 0.7296, 0.7155, 0.7083, 0.7283, 0.6222, 0.4918, 0.3143, 0.2407, 0.3394, 0.3374, -0.0077, 0.1908, 0.3316, -0.1429, -0.2326, -0.1627, -0.0844]}, \"token.table\": {\"Topic\": [1, 2, 3, 8, 9, 2, 4, 5, 6, 7, 9, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 6, 9, 1, 5, 6, 9, 1, 2, 5, 6, 9, 1, 3, 4, 6, 7, 8, 3, 4, 5, 7, 8, 9, 4, 5, 7, 8, 9, 2, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 7, 8, 9, 1, 4, 5, 6, 9, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 3, 5, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 8, 9, 1, 2, 5, 6, 7, 9, 1, 2, 3, 4, 6, 9, 1, 2, 3, 5, 6, 8, 9, 1, 4, 5, 7, 8, 9, 2, 4, 5, 6, 7, 9, 1, 3, 5, 6, 7, 9, 2, 4, 5, 6, 9, 1, 2, 3, 4, 6, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 5, 7, 8, 9, 1, 2, 5, 6, 7, 9, 1, 2, 3, 5, 6, 7, 9, 2, 6, 8, 9, 2, 3, 4, 6, 9, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 5, 6, 1, 2, 3, 9, 5, 6, 1, 2, 4, 5, 6, 7, 8, 9, 1, 2, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 2, 4, 5, 7, 8, 1, 3, 4, 8, 1, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 6, 7, 9, 4, 7, 8, 1, 3, 7, 8, 1, 2, 4, 5, 6, 7, 9, 4, 5, 6, 7, 8, 9, 2, 3, 5, 7, 9, 3, 6, 8, 2, 4, 5, 6, 7, 8, 9, 1, 2, 5, 7, 9, 1, 2, 3, 5, 6, 8, 9, 1, 5, 6, 8, 9, 1, 5, 8, 9, 1, 2, 6, 8, 1, 2, 3, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 7, 9, 1, 3, 4, 6, 8, 2, 3, 4, 6, 7, 9, 1, 2, 4, 5, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 6, 7, 8, 9, 1, 3, 5, 7, 9, 1, 3, 5, 6, 7, 8, 9, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 6, 1, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 3, 4, 5, 6, 9, 3, 4, 5, 7, 8, 9, 2, 3, 4, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 4, 5, 6, 7, 8, 1, 2, 4, 5, 7, 8, 9, 2, 4, 5, 7, 8, 9, 1, 3, 4, 7, 9, 1, 2, 3, 5, 6, 7, 9, 1, 5, 6, 7, 9, 1, 3, 5, 6, 9, 1, 3, 5, 6, 9, 1, 3, 4, 5, 9, 1, 2, 3, 5, 6, 8, 9, 3, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 6, 7, 9, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 6, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 6, 7, 9, 3, 5, 6, 8, 9, 1, 2, 3, 9, 1, 2, 4, 5, 6, 7, 9, 1, 2, 6, 9, 1, 3, 5, 6, 1, 2, 3, 7, 9, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 6, 7, 9, 1, 3, 6, 9, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 6, 8, 1, 3, 4, 5, 6, 7, 9, 1, 3, 5, 6, 7, 8, 9, 1, 2, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 8, 9, 1, 3, 5, 6, 9, 1, 2, 4, 5, 7, 9, 1, 2, 9, 1, 2, 3, 4, 6, 9, 1, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 5, 7, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 4, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 4, 5, 6, 7, 8, 9, 1, 3, 5, 6, 7, 8, 9, 2, 3, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 6, 7, 9, 4, 5, 6, 7, 8, 9, 3, 5, 7, 8, 9, 3, 5, 6, 1, 2, 3, 4, 5, 7, 8, 9, 1, 3, 4, 5, 7, 8, 2, 3, 4, 6, 7, 8, 9, 1, 2, 4, 6, 8, 9, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 6, 7, 9, 1, 2, 3, 6, 7, 8, 9, 1, 2, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 1, 3, 4, 5, 6, 9, 1, 2, 4, 5, 7, 9, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 7, 8, 9, 1, 3, 4, 5, 6, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 3, 4, 5, 6, 8, 1, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 8, 9, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 6, 1, 4, 6, 7, 9, 1, 2, 3, 4, 5, 7, 8, 9, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 8, 9, 1, 3, 4, 5, 6, 7, 8, 9, 4, 5, 7, 9, 1, 6, 7, 9, 4, 5, 6, 7, 9, 1, 2, 5, 7, 9, 1, 6, 8, 9, 2, 3, 5, 6, 8, 9, 1, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 2, 3, 5, 6, 7, 3, 5, 6, 7, 8, 9, 1, 2, 4, 5, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 2, 3, 6, 7, 8, 3, 4, 6, 7, 2, 3, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 6, 7, 3, 4, 5, 8, 9, 1, 2, 6, 8, 9, 2, 3, 4, 5, 8, 9, 1, 3, 4, 6, 7, 8, 9, 2, 3, 6, 7, 9, 1, 4, 6, 7, 9, 2, 3, 4, 7, 9, 1, 2, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 6, 7, 9, 2, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 6, 7, 8, 9, 2, 5, 6, 9, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 6, 9, 1, 6, 8, 9, 1, 2, 3, 6, 9, 1, 3, 5, 6, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 6, 7, 8, 9, 1, 2, 5, 9, 4, 5, 6, 8, 9, 1, 2, 5, 6, 9, 4, 6, 7, 9, 1, 2, 5, 7, 9, 1, 6, 8, 9, 3, 5, 6, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 3, 5, 6, 8, 9, 4, 8, 9, 1, 2, 3, 7, 8, 9, 1, 4, 6, 7, 9, 1, 2, 3, 6, 9, 1, 2, 5, 7, 8, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 3, 4, 5, 6, 7, 1, 2, 3, 6, 8, 9, 1, 2, 6, 8, 9, 1, 3, 4, 6, 9, 1, 3, 6, 9, 1, 3, 4, 5, 6, 9, 1, 2, 3, 7, 8, 9, 2, 3, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 4, 6, 8, 9, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 6, 7, 8, 9, 1, 2, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 9, 1, 2, 3, 4, 9, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 8, 1, 2, 3, 9], \"Freq\": [0.20026167891096905, 0.06675389297032301, 0.3003925183664536, 0.033376946485161506, 0.3671464113367766, 0.03949703408092667, 0.07899406816185334, 0.11849110224278, 0.35547330672834, 0.07899406816185334, 0.31597627264741335, 0.12887371454075355, 0.014319301615639284, 0.057277206462557136, 0.014319301615639284, 0.15751231777203212, 0.44389835008481776, 0.014319301615639284, 0.17183161938767139, 0.05153948713432318, 0.05153948713432318, 0.05153948713432318, 0.2576974356716159, 0.5153948713432318, 0.13889349485383842, 0.324084821325623, 0.41668048456151524, 0.04629783161794614, 0.2670025323728877, 0.05340050647457753, 0.3204030388474652, 0.21360202589831012, 0.05340050647457753, 0.5727542873726801, 0.14318857184317002, 0.04772952394772334, 0.04772952394772334, 0.14318857184317002, 0.04772952394772334, 0.013161749898050969, 0.2632349979610194, 0.3422054973493252, 0.2105879983688155, 0.06580874949025485, 0.07897049938830582, 0.1855306960257466, 0.2782960440386199, 0.0927653480128733, 0.04638267400643665, 0.3865222833869721, 0.08157449211649886, 0.36708521452424486, 0.1223617381747483, 0.20393623029124716, 0.08157449211649886, 0.1223617381747483, 0.13829377561530495, 0.0921958504102033, 0.0921958504102033, 0.07375668032816264, 0.05531751024612198, 0.16595253073836594, 0.1843917008204066, 0.04609792520510165, 0.1567329456973456, 0.22398447376971936, 0.07466149125657312, 0.04977432750438208, 0.5724047663003939, 0.04977432750438208, 0.02488716375219104, 0.12008931536246902, 0.36026794608740703, 0.18013397304370352, 0.06004465768123451, 0.24017863072493803, 0.15347704614182128, 0.2046360615224284, 0.2046360615224284, 0.2557950769030355, 0.1023180307612142, 0.0511590153806071, 0.10543734151191267, 0.057511277188316, 0.10543734151191267, 0.12460776724135134, 0.28755638594158, 0.13419298010607067, 0.04792606432359667, 0.038340851458877334, 0.10543734151191267, 0.23497731887032858, 0.046995463774065716, 0.09399092754813143, 0.3759637101925257, 0.046995463774065716, 0.18798185509626286, 0.08202884609534138, 0.05468589739689425, 0.12304326914301207, 0.04101442304767069, 0.1914006408891299, 0.06835737174611782, 0.12304326914301207, 0.06835737174611782, 0.24608653828602414, 0.3161191287243544, 0.10537304290811812, 0.56198956217663, 0.32230264841305517, 0.06043174657744784, 0.20143915525815947, 0.020143915525815948, 0.2618709018356073, 0.020143915525815948, 0.08057566210326379, 0.020143915525815948, 0.048991892539651444, 0.9145153274068268, 0.01633063084655048, 0.24684117810569414, 0.1851308835792706, 0.08228039270189805, 0.12342058905284707, 0.10285049087737255, 0.041140196350949024, 0.041140196350949024, 0.1851308835792706, 0.11637945013186034, 0.027383400031025962, 0.09584190010859087, 0.0753043500853214, 0.04792095005429543, 0.08215020009307789, 0.0753043500853214, 0.10268775011634736, 0.37652175042660696, 0.6426320752140451, 0.025705283008561803, 0.025705283008561803, 0.07711584902568541, 0.051410566017123606, 0.1799369810599326, 0.145380473272615, 0.018172559159076875, 0.03634511831815375, 0.21807070990892247, 0.4724865381359987, 0.10903535495446123, 0.28849045256447153, 0.247277530769547, 0.0412129217949245, 0.082425843589849, 0.0412129217949245, 0.28849045256447153, 0.44336359993040897, 0.28001911574552146, 0.02333492631212679, 0.02333492631212679, 0.02333492631212679, 0.09333970524850715, 0.11667463156063394, 0.14431834321890155, 0.19242445762520208, 0.04810611440630052, 0.2886366864378031, 0.09621222881260104, 0.24053057203150258, 0.03398892909985505, 0.0679778581997101, 0.40786714919826056, 0.03398892909985505, 0.10196678729956514, 0.3398892909985505, 0.09883029320615547, 0.09883029320615547, 0.3623777417559034, 0.13177372427487397, 0.03294343106871849, 0.26354744854974793, 0.2865749923490432, 0.10420908812692481, 0.2344704482855808, 0.20841817625384962, 0.130261360158656, 0.04952764371647378, 0.037145732787355334, 0.037145732787355334, 0.061909554645592224, 0.09905528743294756, 0.2971658622988427, 0.4209849715900271, 0.2918063073278534, 0.37286361491892384, 0.06484584607285632, 0.11348023062749855, 0.03242292303642816, 0.01621146151821408, 0.01621146151821408, 0.09726876910928448, 0.15203911618034846, 0.08687949496019913, 0.021719873740049783, 0.3475179798407965, 0.043439747480099565, 0.1085993687002489, 0.2389186111405476, 0.02849669717042257, 0.05699339434084514, 0.08549009151126771, 0.08549009151126771, 0.6554240349197191, 0.08549009151126771, 0.05427792053620346, 0.02713896026810173, 0.08141688080430519, 0.08141688080430519, 0.02713896026810173, 0.5156402450939328, 0.1899727218767121, 0.035709080305469605, 0.14283632122187842, 0.14283632122187842, 0.6427634454984529, 0.08011559088280674, 0.1602311817656135, 0.12017338632421012, 0.4806935452968405, 0.12017338632421012, 0.11539311665526852, 0.17308967498290279, 0.11539311665526852, 0.05769655832763426, 0.34617934996580557, 0.11539311665526852, 0.11539311665526852, 0.07940482031426815, 0.07940482031426815, 0.07940482031426815, 0.1588096406285363, 0.5558337421998771, 0.18228120419626836, 0.6076040139875613, 0.12152080279751223, 0.06076040139875612, 0.6787330351763048, 0.3054298658293372, 0.010360754988687663, 0.010360754988687663, 0.14505056984162726, 0.06216452993212598, 0.20721509977375324, 0.0828860399095013, 0.020721509977375326, 0.47659472947963244, 0.14338240034897168, 0.04779413344965723, 0.23897066724828614, 0.43014720104691506, 0.09558826689931446, 0.09558826689931446, 0.23224369841813888, 0.004838410383711227, 0.06289933498824594, 0.01935364153484491, 0.01451523115113368, 0.17418277381360417, 0.2177284672670052, 0.01935364153484491, 0.2515973399529838, 0.26480346842640096, 0.06968512327010551, 0.027874049308042204, 0.027874049308042204, 0.04181107396206331, 0.32055156704248533, 0.11149619723216882, 0.013937024654021102, 0.09755917257814771, 0.3695409713683643, 0.014213114283398626, 0.07106557141699313, 0.028426228566797253, 0.08527868570039175, 0.14213114283398626, 0.042639342850195876, 0.24162294281777666, 0.5243281461540575, 0.0873880243590096, 0.0873880243590096, 0.218470060897524, 0.0436940121795048, 0.08961157649486892, 0.5376694589692135, 0.328575780481186, 0.02987052549828964, 0.011494507132724754, 0.01724176069908713, 0.04023077496453664, 0.13218683202633466, 0.09770331062816041, 0.32184619971629314, 0.37357148181355454, 0.25065838302619614, 0.013192546475062954, 0.09234782532544067, 0.026385092950125907, 0.18469565065088134, 0.11873291827556658, 0.07915527885037772, 0.06596273237531476, 0.14511801122569248, 0.2380360631624402, 0.05950901579061005, 0.17852704737183014, 0.41656311053427036, 0.030118204505083405, 0.7830733171321685, 0.18070922703050044, 0.05673892736808164, 0.11347785473616329, 0.34043356420848986, 0.3971724915765715, 0.014108451984579077, 0.04232535595373723, 0.05643380793831631, 0.733639503198112, 0.014108451984579077, 0.028216903969158155, 0.11286761587663262, 0.060000526656670126, 0.30000263328335064, 0.060000526656670126, 0.12000105331334025, 0.060000526656670126, 0.3600031599400208, 0.05369408968173005, 0.05369408968173005, 0.2147763587269202, 0.2147763587269202, 0.3758586277721103, 0.3680192800606527, 0.6095319326004561, 0.011500602501895397, 0.06741074203348667, 0.04494049468899111, 0.3595239575119289, 0.13482148406697333, 0.33705371016743335, 0.04494049468899111, 0.022470247344495556, 0.09246860870084027, 0.030822869566946756, 0.06164573913389351, 0.8013946087406156, 0.030822869566946756, 0.28279311389108563, 0.028279311389108563, 0.056558622778217126, 0.19795517972375995, 0.28279311389108563, 0.028279311389108563, 0.11311724555643425, 0.47862958620513707, 0.19145183448205483, 0.09572591724102741, 0.04786295862051371, 0.14358887586154112, 0.2616958047313709, 0.5607767244243661, 0.07477022992324882, 0.07477022992324882, 0.5315107517279424, 0.1449574777439843, 0.19327663699197906, 0.048319159247994764, 0.33882220856047973, 0.0484031726514971, 0.0968063453029942, 0.0484031726514971, 0.3872253812119768, 0.3515483307882705, 0.03348079340840671, 0.13392317363362685, 0.016740396704203356, 0.06696158681681343, 0.10044238022522015, 0.016740396704203356, 0.15066357033783023, 0.13392317363362685, 0.21794114786518873, 0.04358822957303774, 0.13076468871911323, 0.04358822957303774, 0.47947052530341516, 0.13076468871911323, 0.11914917676310105, 0.4468094128616289, 0.32766023609852785, 0.029787294190775263, 0.059574588381550525, 0.04727468859206157, 0.015758229530687187, 0.015758229530687187, 0.04727468859206157, 0.7879114765343594, 0.07879114765343595, 0.5041545676306968, 0.15512448234790668, 0.03878112058697667, 0.03878112058697667, 0.11634336176093002, 0.11634336176093002, 0.14677962878180822, 0.22016944317271234, 0.11008472158635617, 0.14677962878180822, 0.07338981439090411, 0.1834745359772603, 0.036694907195452056, 0.11008472158635617, 0.28128879676124746, 0.2109665975709356, 0.03516109959515593, 0.1054832987854678, 0.2109665975709356, 0.07032219919031187, 0.03516109959515593, 0.5278580577612509, 0.1583574173283753, 0.1055716115522502, 0.1055716115522502, 0.0527858057761251, 0.02745245847321891, 0.10980983389287564, 0.4666917940447215, 0.10980983389287564, 0.19216720931253237, 0.02745245847321891, 0.05490491694643782, 0.05138950199839573, 0.0770842529975936, 0.10277900399679146, 0.12847375499598931, 0.5909792729815508, 0.01523193783373626, 0.01523193783373626, 0.01523193783373626, 0.04569581350120878, 0.22847906750604388, 0.0761596891686813, 0.1827832540048351, 0.1523193783373626, 0.2589429431735164, 0.6325805142690624, 0.3162902571345312, 0.2539485921435979, 0.14511348122491308, 0.21767022183736962, 0.14511348122491308, 0.10883511091868481, 0.10883511091868481, 0.4252280156477698, 0.07731418466323087, 0.07731418466323087, 0.05798563849742315, 0.038657092331615434, 0.05798563849742315, 0.2126140078238849, 0.038657092331615434, 0.6454870790824565, 0.06586602847780168, 0.02634641139112067, 0.05269282278224134, 0.14490526265116369, 0.05269282278224134, 0.04878731136610487, 0.2927238681966292, 0.04878731136610487, 0.1463619340983146, 0.09757462273220974, 0.39029849092883895, 0.1145346759234511, 0.05726733796172555, 0.17180201388517663, 0.1145346759234511, 0.05726733796172555, 0.51540604165553, 0.1187158359147963, 0.02374316718295926, 0.14245900309775555, 0.1899453374636741, 0.3086611733784704, 0.02374316718295926, 0.09497266873183705, 0.07122950154887778, 0.04748633436591852, 0.18273338843292408, 0.07309335537316963, 0.2192800661195089, 0.10964003305975445, 0.29237342149267853, 0.036546677686584816, 0.10964003305975445, 0.08901099484019344, 0.07120879587215474, 0.05340659690411606, 0.10681319380823212, 0.6052747649133153, 0.017802198968038686, 0.05340659690411606, 0.05197691264402857, 0.025988456322014283, 0.3378499321861857, 0.2858730195421571, 0.05197691264402857, 0.23389610689812856, 0.3397276822534883, 0.16986384112674416, 0.2831064018779069, 0.05662128037558139, 0.11324256075116278, 0.2945258811063924, 0.06200544865397734, 0.03100272432698867, 0.015501362163494336, 0.015501362163494336, 0.5580490378857961, 0.015501362163494336, 0.4981516244123106, 0.14944548732369317, 0.09963032488246212, 0.19926064976492425, 0.04981516244123106, 0.2358697441564546, 0.32432089821512505, 0.029483718019556824, 0.2653534621760114, 0.1474185900977841, 0.6150489411982015, 0.09711299071550551, 0.064741993810337, 0.09711299071550551, 0.09711299071550551, 0.18207999585388362, 0.36415999170776725, 0.18207999585388362, 0.12138666390258909, 0.12138666390258909, 0.19400057696752848, 0.0149231213051945, 0.6118479735129745, 0.029846242610389, 0.07461560652597249, 0.0149231213051945, 0.0447693639155835, 0.2793512794954529, 0.17190847968950948, 0.34381695937901896, 0.1504199197283208, 0.04297711992237737, 0.05649017287776864, 0.22596069151107456, 0.22596069151107456, 0.02824508643888432, 0.05649017287776864, 0.19771560507219024, 0.08473525931665296, 0.05649017287776864, 0.05649017287776864, 0.22916871013660225, 0.057292177534150564, 0.22916871013660225, 0.11458435506830113, 0.2864608876707528, 0.057292177534150564, 0.03248145219133862, 0.01624072609566931, 0.01624072609566931, 0.06496290438267724, 0.03248145219133862, 0.27609234362637824, 0.4872217828700793, 0.09744435657401586, 0.07717642058720749, 0.04287578921511526, 0.18007831470348412, 0.06002610490116137, 0.2572547352906916, 0.26582989313371463, 0.06002610490116137, 0.02572547352906916, 0.02572547352906916, 0.0967782631058609, 0.0967782631058609, 0.0967782631058609, 0.1935565262117218, 0.4355021839763741, 0.04838913155293045, 0.08943666753762894, 0.035774667015051574, 0.035774667015051574, 0.25042266910536104, 0.1609860015677321, 0.12521133455268052, 0.07154933403010315, 0.21464800209030946, 0.43160732902765536, 0.04110545990739575, 0.05138182488424469, 0.31856731428231705, 0.0822109198147915, 0.010276364976848938, 0.020552729953697876, 0.04110545990739575, 0.03639771499609271, 0.36397714996092717, 0.027298286247069536, 0.022748571872557948, 0.37762629308446194, 0.013649143123534768, 0.018198857498046356, 0.14559085998437085, 0.023137232285480556, 0.023137232285480556, 0.48588187799509164, 0.3007840197112472, 0.1619606259983639, 0.09399090546400962, 0.16448408456201682, 0.5521965696010565, 0.07049317909800722, 0.10573976864701082, 0.20809991694721924, 0.33295986711555076, 0.041619983389443845, 0.3745798505049946, 0.4627971999582378, 0.03856643332985315, 0.03856643332985315, 0.11569929998955945, 0.03856643332985315, 0.11569929998955945, 0.1542657333194126, 0.45856292713021923, 0.1528543090434064, 0.1528543090434064, 0.20380574539120855, 0.592252501077998, 0.17767575032339938, 0.1184505002155996, 0.0592252501077998, 0.10157990112862071, 0.15236985169293107, 0.15236985169293107, 0.45710955507879325, 0.050789950564310356, 0.20600551797525943, 0.10300275898762971, 0.12875344873453715, 0.07725206924072228, 0.12875344873453715, 0.10300275898762971, 0.20600551797525943, 0.05150137949381486, 0.03264232378058228, 0.11424813323203797, 0.01632116189029114, 0.06528464756116456, 0.11424813323203797, 0.04896348567087341, 0.17953278079320253, 0.19585394268349365, 0.2448174283543671, 0.06798714757640945, 0.1359742951528189, 0.37392931167025195, 0.2719485903056378, 0.06798714757640945, 0.06798714757640945, 0.3352421983511252, 0.07057730491602635, 0.22937624097708564, 0.052932978687019766, 0.1411546098320527, 0.017644326229006586, 0.017644326229006586, 0.03528865245801317, 0.10586595737403953, 0.2840389081215742, 0.4733981802026236, 0.0631197573603498, 0.0315598786801749, 0.0315598786801749, 0.1262395147206996, 0.268678629028821, 0.0537357258057642, 0.4298858064461136, 0.2149429032230568, 0.6732532185337586, 0.15090158346446314, 0.07351615604678974, 0.00386927137088367, 0.011607814112651011, 0.03482344233795303, 0.046431256450604044, 0.39156660998442916, 0.12204673557956235, 0.09662033233382018, 0.005085280649148431, 0.005085280649148431, 0.13221729687785921, 0.025426403245742156, 0.06610864843892961, 0.15764370012360135, 0.48592724930877784, 0.32395149953918523, 0.1889717080645247, 0.02260853279330144, 0.02260853279330144, 0.09043413117320576, 0.02260853279330144, 0.02260853279330144, 0.6782559837990432, 0.13565119675980863, 0.01840262366930996, 0.01840262366930996, 0.01840262366930996, 0.3312472260475793, 0.3864550970555092, 0.03680524733861992, 0.20242886036240956, 0.12848326644245564, 0.08565551096163711, 0.17131102192327421, 0.12848326644245564, 0.38544979932736695, 0.08565551096163711, 0.12645527816617405, 0.017563233078635283, 0.01053793984718117, 0.059714992467359965, 0.3020876089525269, 0.049177052620178796, 0.18265762401780694, 0.07025293231454113, 0.18265762401780694, 0.15271598604425163, 0.07635799302212581, 0.38178996511062907, 0.22907397906637744, 0.11453698953318872, 0.10336872218633542, 0.18606369993540373, 0.06202123331180125, 0.10336872218633542, 0.2274111888099379, 0.10336872218633542, 0.2274111888099379, 0.03755208315589294, 0.3004166652471435, 0.1877604157794647, 0.11265624946767883, 0.15020833262357175, 0.03755208315589294, 0.1877604157794647, 0.1711031853313969, 0.1711031853313969, 0.08555159266569845, 0.12832738899854768, 0.384982166995643, 0.028409286568590385, 0.05681857313718077, 0.05681857313718077, 0.028409286568590385, 0.7102321642147597, 0.08522785970577115, 0.8340490014369742, 0.11584013908846864, 0.023168027817693726, 0.055190002282898734, 0.01839666742763291, 0.03679333485526582, 0.01839666742763291, 0.01839666742763291, 0.8462467016711139, 0.0568438224000473, 0.13263558560011038, 0.4736985200003942, 0.01894794080001577, 0.15158352640012615, 0.01894794080001577, 0.13263558560011038, 0.229627352027744, 0.114813676013872, 0.229627352027744, 0.07654245067591467, 0.038271225337957335, 0.114813676013872, 0.038271225337957335, 0.15308490135182934, 0.10382979930110907, 0.3460993310036969, 0.03460993310036969, 0.20765959860221814, 0.13843973240147875, 0.13843973240147875, 0.018250456424660506, 0.14600365139728405, 0.05475136927398152, 0.03650091284932101, 0.16425410782194455, 0.14600365139728405, 0.16425410782194455, 0.2555063899452471, 0.31886174297210734, 0.03985771787151342, 0.01992885893575671, 0.11957315361454027, 0.47829261445816107, 0.04738419629420738, 0.14215258888262214, 0.056861035553048854, 0.0379073570353659, 0.14215258888262214, 0.14215258888262214, 0.2843051777652443, 0.10424523184725623, 0.04738419629420738, 0.04919614517553217, 0.019678458070212866, 0.1180707484212772, 0.1475884355265965, 0.0885530613159579, 0.1475884355265965, 0.2656591839478737, 0.1475884355265965, 0.2011952519627485, 0.3269422844394663, 0.025149406495343564, 0.2011952519627485, 0.05029881299068713, 0.07544821948603068, 0.1257470324767178, 0.06350552539485413, 0.031752762697427064, 0.12701105078970826, 0.4445386777639789, 0.1905165761845624, 0.12701105078970826, 0.17824480670420417, 0.02228060083802552, 0.06684180251407656, 0.04456120167605104, 0.04456120167605104, 0.26736721005630626, 0.06684180251407656, 0.11140300419012762, 0.17824480670420417, 0.1689369151611412, 0.07508307340495164, 0.2252492202148549, 0.1877076835123791, 0.05631230505371373, 0.01877076835123791, 0.1689369151611412, 0.09385384175618955, 0.43828835463778715, 0.10518920511306892, 0.03506306837102297, 0.10518920511306892, 0.05259460255653446, 0.017531534185511486, 0.15778380766960337, 0.10518920511306892, 0.22092125619451902, 0.22092125619451902, 0.16569094214588928, 0.11046062809725951, 0.055230314048629756, 0.11046062809725951, 0.055230314048629756, 0.08535827184221058, 0.017071654368442116, 0.1024299262106527, 0.15364488931597903, 0.18778819805286326, 0.05121496310532635, 0.08535827184221058, 0.06828661747376846, 0.25607481552663175, 0.3119861024447448, 0.0389982628055931, 0.058497394208389654, 0.0779965256111862, 0.46797915366711723, 0.0389982628055931, 0.05011142682225053, 0.6013371218670064, 0.1503342804667516, 0.01670380894075018, 0.01670380894075018, 0.1503342804667516, 0.18212852000358537, 0.12141901333572357, 0.18212852000358537, 0.30354753333930895, 0.18212852000358537, 0.10245107365173112, 0.5634809050845212, 0.2561276841293278, 0.22969673528428056, 0.3445451029264208, 0.02871209191053507, 0.02871209191053507, 0.20098464337374547, 0.0861362757316052, 0.02871209191053507, 0.05742418382107014, 0.01716500749252073, 0.08582503746260363, 0.5492802397606633, 0.10299004495512436, 0.05149502247756218, 0.188815082417728, 0.10354706463793975, 0.034515688212646584, 0.4487039467644056, 0.06903137642529317, 0.06903137642529317, 0.24160981748852609, 0.034515688212646584, 0.15459422669011777, 0.051531408896705926, 0.051531408896705926, 0.051531408896705926, 0.2061256355868237, 0.4122512711736474, 0.438811114656503, 0.05485138933206288, 0.10970277866412576, 0.05485138933206288, 0.16455416799618863, 0.10970277866412576, 0.08227708399809432, 0.13607059870591448, 0.09719328478993891, 0.029157985436981674, 0.08747395631094503, 0.1166319417479267, 0.029157985436981674, 0.15550925566390225, 0.048596642394969455, 0.30129918284881063, 0.556943652086326, 0.061882628009591774, 0.04125508533972785, 0.3094131400479589, 0.020627542669863923, 0.3401451919358856, 0.028345432661323798, 0.014172716330661899, 0.0425181489919857, 0.4818723552425046, 0.014172716330661899, 0.056690865322647596, 0.21884781359942246, 0.18237317799951872, 0.18237317799951872, 0.07294927119980749, 0.14589854239961497, 0.07294927119980749, 0.07294927119980749, 0.3917313438035869, 0.07731539680333951, 0.020617439147557204, 0.10824155552467532, 0.03608051850822511, 0.08762411637711812, 0.11339591531156462, 0.010308719573778602, 0.15978515339356833, 0.12948082190388066, 0.2589616438077613, 0.06474041095194033, 0.12948082190388066, 0.06474041095194033, 0.12948082190388066, 0.2589616438077613, 0.08904502913071846, 0.04452251456535923, 0.08904502913071846, 0.1335675436960777, 0.04452251456535923, 0.08904502913071846, 0.04452251456535923, 0.4007026310882331, 0.14299978100139005, 0.057199912400556024, 0.028599956200278012, 0.057199912400556024, 0.057199912400556024, 0.34319947440333615, 0.08579986860083404, 0.2287996496022241, 0.18940108872591924, 0.037880217745183846, 0.11364065323555153, 0.2651615242162869, 0.3409219597066546, 0.07576043549036769, 0.4108436699739218, 0.051355458746740225, 0.30813275248044136, 0.2054218349869609, 0.18102745200386997, 0.15085621000322497, 0.060342484001289984, 0.12068496800257997, 0.36205490400773993, 0.12068496800257997, 0.04790990054075756, 0.1437297016222727, 0.04790990054075756, 0.09581980108151512, 0.6228287070298484, 0.04790990054075756, 0.17064083988211493, 0.017064083988211493, 0.13651267190569194, 0.11944858791748045, 0.034128167976422985, 0.29008942779959535, 0.05119225196463448, 0.15357675589390343, 0.09839482254916886, 0.09839482254916886, 0.25582653862783905, 0.07871585803933509, 0.11807378705900264, 0.039357929019667545, 0.31486343215734036, 0.09629756591625196, 0.1283967545550026, 0.41728945230375847, 0.09629756591625196, 0.03209918863875065, 0.19259513183250393, 0.11157843633601126, 0.027894609084002816, 0.08368382725200846, 0.027894609084002816, 0.2510514817560254, 0.05578921816800563, 0.22315687267202253, 0.22315687267202253, 0.08955678225432268, 0.17911356450864535, 0.134335173381484, 0.2238919556358067, 0.268670346762968, 0.04477839112716134, 0.05067811583822218, 0.45610304254399964, 0.10135623167644436, 0.05067811583822218, 0.2533905791911109, 0.10135623167644436, 0.06884948482542738, 0.08261938179051287, 0.13769896965085476, 0.06884948482542738, 0.11015917572068382, 0.13769896965085476, 0.11015917572068382, 0.19277855751119669, 0.08261938179051287, 0.0506789356261543, 0.12669733906538574, 0.22805521031769435, 0.07601840343923146, 0.17737627469154005, 0.329413081570003, 0.18700707758554713, 0.015583923132128929, 0.3272623857747075, 0.2960945395104497, 0.14025530818916035, 0.015583923132128929, 0.015583923132128929, 0.5132155280365363, 0.2993757246879795, 0.08553592133942271, 0.08553592133942271, 0.02666337412738979, 0.07999012238216938, 0.02666337412738979, 0.8265645979490835, 0.02666337412738979, 0.4485741732938996, 0.044857417329389956, 0.022428708664694978, 0.044857417329389956, 0.08971483465877991, 0.044857417329389956, 0.044857417329389956, 0.26914450397633977, 0.19631598433641814, 0.19631598433641814, 0.19631598433641814, 0.13087732289094542, 0.06543866144547271, 0.26175464578189084, 0.01535330540991547, 0.12282644327932377, 0.06141322163966188, 0.01535330540991547, 0.522012383937126, 0.046059916229746416, 0.03070661081983094, 0.046059916229746416, 0.13817974868923924, 0.7539795020923407, 0.17592855048821282, 0.02513265006974469, 0.02513265006974469, 0.01856814527521285, 0.027852217912819277, 0.01856814527521285, 0.009284072637606425, 0.1856814527521285, 0.0371362905504257, 0.08355665373845783, 0.6127487940820241, 0.01110060972385643, 0.01110060972385643, 0.16650914585784646, 0.799243900117663, 0.2346631365606825, 0.17599735242051187, 0.4106604889811944, 0.11733156828034125, 0.05825707004906169, 0.029128535024530847, 0.029128535024530847, 0.757341910637802, 0.08738560507359254, 0.17907371737708888, 0.02238421467213611, 0.6939106548362194, 0.04476842934427222, 0.04476842934427222, 0.5042925929757187, 0.12607314824392968, 0.06303657412196484, 0.18910972236589452, 0.16404660308819638, 0.10936440205879758, 0.32809320617639276, 0.10936440205879758, 0.05468220102939879, 0.21872880411759515, 0.07201432796502154, 0.19803940190380923, 0.1080214919475323, 0.19803940190380923, 0.14402865593004308, 0.09001790995627693, 0.18003581991255385, 0.07283325164661648, 0.060694376372180406, 0.14566650329323297, 0.03641662582330824, 0.2670552560375938, 0.16994425384210513, 0.01213887527443608, 0.03641662582330824, 0.19422200439097728, 0.2492706224925807, 0.062317655623145174, 0.12463531124629035, 0.031158827811572587, 0.062317655623145174, 0.12463531124629035, 0.18695296686943552, 0.15579413905786293, 0.09818483960980373, 0.19636967921960746, 0.2945545188294112, 0.2945545188294112, 0.09818483960980373, 0.18841680162084518, 0.09420840081042259, 0.6359067054703524, 0.047104200405211294, 0.023552100202605647, 0.023552100202605647, 0.046380023285628444, 0.09276004657125689, 0.18552009314251378, 0.046380023285628444, 0.27828013971377064, 0.09276004657125689, 0.27828013971377064, 0.15943532805857244, 0.023915299208785868, 0.03985883201464311, 0.03188706561171449, 0.14349179525271522, 0.1355200288497866, 0.09566119683514347, 0.37467302093764526, 0.07218602903716631, 0.10827904355574947, 0.21655808711149893, 0.5413952177787473, 0.036093014518583155, 0.5009513393222781, 0.035782238523019864, 0.21469343113811917, 0.21469343113811917, 0.43745783346346623, 0.14581927782115542, 0.21872891673173311, 0.10936445836586656, 0.07290963891057771, 0.22694450730050367, 0.1361667043803022, 0.18155560584040292, 0.011347225365025183, 0.17020838047537776, 0.03404167609507555, 0.022694450730050365, 0.22694450730050367, 0.5246758367951996, 0.1311689591987999, 0.04372298639959997, 0.04372298639959997, 0.21861493199799983, 0.17245991631076596, 0.21557489538845745, 0.21557489538845745, 0.17245991631076596, 0.21557489538845745, 0.06314851987266334, 0.06314851987266334, 0.31574259936331667, 0.5051881589813068, 0.03157425993633167, 0.09489631065834513, 0.15816051776390855, 0.2530568284222537, 0.09489631065834513, 0.2530568284222537, 0.15816051776390855, 0.04302002781217929, 0.12906008343653788, 0.12906008343653788, 0.04302002781217929, 0.021510013906089646, 0.08604005562435858, 0.5377503476522412, 0.031404391380026875, 0.1570219569001344, 0.031404391380026875, 0.031404391380026875, 0.7537053931206451, 0.26638814230776386, 0.3196657707693167, 0.053277628461552776, 0.053277628461552776, 0.15983288538465834, 0.06884500024559226, 0.03442250012279613, 0.13769000049118452, 0.03442250012279613, 0.7228725025787187, 0.8251426313735973, 0.05157141446084983, 0.10314282892169967, 0.017190471486949944, 0.17500326917183573, 0.09423252955406539, 0.03365447484073764, 0.1211561094266555, 0.02692357987259011, 0.1413487943310981, 0.1211561094266555, 0.06057805471332775, 0.22211953394886844, 0.23791046730675672, 0.03965174455112612, 0.07930348910225224, 0.31721395640900896, 0.2775622118578828, 0.03965174455112612, 0.06086434847916829, 0.18259304543750485, 0.24345739391667315, 0.24345739391667315, 0.18259304543750485, 0.1372011628187099, 0.019600166116958556, 0.11760099670175134, 0.03920033223391711, 0.3920033223391711, 0.15680132893566845, 0.05880049835087567, 0.09800083058479278, 0.432070053038366, 0.05891864359614081, 0.03927909573076054, 0.01963954786538027, 0.11783728719228162, 0.25531412224994354, 0.03927909573076054, 0.03927909573076054, 0.2978197890351597, 0.24818315752929976, 0.04963663150585995, 0.3970930520468796, 0.21139231616124135, 0.10569615808062068, 0.035232052693540225, 0.21139231616124135, 0.21139231616124135, 0.07046410538708045, 0.035232052693540225, 0.1409282107741609, 0.06853394676031385, 0.034266973380156926, 0.25700230035117694, 0.08566743345039231, 0.25700230035117694, 0.08566743345039231, 0.1370678935206277, 0.034266973380156926, 0.05140046007023539, 0.079856513168672, 0.19964128292168, 0.119784769753008, 0.039928256584336, 0.59892384876504, 0.4512616205617429, 0.16922310771065358, 0.33844621542130715, 0.05640770257021786, 0.008389718986330822, 0.016779437972661643, 0.4446551062755335, 0.3439784784395637, 0.18457381769927808, 0.13313685920381857, 0.17751581227175808, 0.5325474368152743, 0.13313685920381857, 0.2285957123763303, 0.05714892809408258, 0.17144678428224774, 0.11429785618816515, 0.28574464047041287, 0.05714892809408258, 0.05714892809408258, 0.2454270408685399, 0.02887376951394587, 0.07218442378486467, 0.0649659814063782, 0.07218442378486467, 0.15880573232670228, 0.08662130854183761, 0.014436884756972935, 0.2598639256255128, 0.10294906135243585, 0.15442359202865377, 0.10294906135243585, 0.30884718405730754, 0.10294906135243585, 0.051474530676217926, 0.15442359202865377, 0.1527485038068592, 0.190935629758574, 0.1527485038068592, 0.45824551142057757, 0.07724824395937058, 0.07724824395937058, 0.03862412197968529, 0.7724824395937058, 0.03862412197968529, 0.5045176706794502, 0.08408627844657503, 0.08408627844657503, 0.16817255689315005, 0.08408627844657503, 0.033719674558739254, 0.23603772191117475, 0.37091642014613174, 0.33719674558739254, 0.2430631832955664, 0.19445054663645311, 0.19445054663645311, 0.14583790997733984, 0.19445054663645311, 0.2502890916675202, 0.27531800083427227, 0.3504047283345283, 0.10011563666700808, 0.6377587688031091, 0.055457284243748614, 0.2772864212187431, 0.07616936714510095, 0.015233873429020191, 0.1523387342902019, 0.060935493716080764, 0.04570162028706057, 0.22850810143530287, 0.41131458258354514, 0.020346069923330875, 0.04069213984666175, 0.14242248946331612, 0.162768559386647, 0.020346069923330875, 0.18311462930997788, 0.4069213984666175, 0.32683982239452936, 0.0632593204634573, 0.1265186409269146, 0.10543220077242882, 0.0632593204634573, 0.010543220077242881, 0.08434576061794305, 0.22140762162210054, 0.39344337200332186, 0.13551938369003308, 0.017486372089036525, 0.03060115115581392, 0.048087523244850446, 0.09180345346744176, 0.021857965111295657, 0.03497274417807305, 0.23169443017973398, 0.03597338984018736, 0.03597338984018736, 0.1798669492009368, 0.03597338984018736, 0.03597338984018736, 0.5755742374429977, 0.07194677968037472, 0.03597338984018736, 0.19069329121475687, 0.19069329121475687, 0.054483797489930534, 0.0817256962348958, 0.4631122786644095, 0.030321902951268964, 0.09096570885380689, 0.849013282635531, 0.0864469184414283, 0.12967037766214246, 0.0864469184414283, 0.1728938368828566, 0.4322345922071415, 0.0864469184414283, 0.21732091973204942, 0.024146768859116603, 0.048293537718233207, 0.603669221477915, 0.09658707543646641, 0.06694731140982037, 0.018258357657223737, 0.8155399753559937, 0.07911954984796953, 0.012172238438149158, 0.03690190621019662, 0.03690190621019662, 0.11070571863058988, 0.6642343117835392, 0.11070571863058988, 0.055834794890890056, 0.3350087693453403, 0.16750438467267015, 0.39084356423623035, 0.031300945216309654, 0.010433648405436553, 0.09390283564892897, 0.031300945216309654, 0.4590805298392083, 0.031300945216309654, 0.04173459362174621, 0.04173459362174621, 0.25040756173047723, 0.2727963246173401, 0.015588361406705149, 0.11691271055028862, 0.023382542110057723, 0.046765084220115445, 0.16367779477040406, 0.03897090351676288, 0.07014762633017317, 0.25720796321063494, 0.3448069743828608, 0.01188989566837451, 0.07926597112249674, 0.06737607545412222, 0.14267874802049413, 0.27346760037261375, 0.015853194224499347, 0.06737607545412222, 0.3084011204104581, 0.2202865145788986, 0.04405730291577972, 0.26434381749467833, 0.04405730291577972, 0.08811460583155944, 0.26637529708658614, 0.01902680693475615, 0.13318764854329307, 0.24734849015183, 0.1522144554780492, 0.17124126241280538, 0.22613839829547625, 0.08223214483471863, 0.1027901810433983, 0.1439062534607576, 0.4111607241735932, 0.01752447357944107, 0.6133565752804374, 0.31544052442993925, 0.03504894715888214, 0.03504894715888214, 0.6396015198144618, 0.1370574685316704, 0.04568582284389013, 0.1370574685316704, 0.7718060081975565, 0.02968484646913679, 0.05936969293827358, 0.014842423234568395, 0.08905453940741037, 0.014842423234568395, 0.4211150119592075, 0.10527875298980187, 0.14739025418572263, 0.21055750597960374, 0.04211150119592075, 0.06316725179388112, 0.13358354005328776, 0.10018765503996582, 0.03339588501332194, 0.20037531007993165, 0.2337711950932536, 0.30056296511989744, 0.013184930084302892, 0.06592465042151446, 0.07910958050581736, 0.03955479025290868, 0.03955479025290868, 0.13184930084302893, 0.18458902118024048, 0.10547944067442314, 0.3428081821918752, 0.22170427122239963, 0.08868170848895986, 0.08868170848895986, 0.08868170848895986, 0.44340854244479927, 0.19340300253961923, 0.07486567840243324, 0.04991045226828883, 0.03743283920121662, 0.18092538947254702, 0.11229851760364987, 0.1497313568048665, 0.03743283920121662, 0.16844777640547481, 0.054645550370734354, 0.054645550370734354, 0.2459049766683046, 0.027322775185367177, 0.08196832555610153, 0.08196832555610153, 0.13661387592683588, 0.32787330222440614, 0.025059742323434518, 0.1503584539406071, 0.012529871161717259, 0.18794806742575887, 0.07517922697030355, 0.5387844599538422, 0.024776837731773183, 0.049553675463546366, 0.012388418865886592, 0.049553675463546366, 0.07433051319531955, 0.39642940370837093, 0.38404098484248433, 0.14939931365761486, 0.14939931365761486, 0.037349828414403714, 0.037349828414403714, 0.522897597801652, 0.07469965682880743, 0.037349828414403714, 0.22088152929418298, 0.04733175627732492, 0.11044076464709149, 0.09466351255464985, 0.0788862604622082, 0.2366587813866246, 0.06310900836976656, 0.14199526883197477, 0.4301467645224666, 0.047794084946940735, 0.023897042473470367, 0.023897042473470367, 0.09558816989388147, 0.09558816989388147, 0.16727929731429256, 0.09558816989388147, 0.30856750746669537, 0.012342700298667814, 0.0863989020906747, 0.02468540059733563, 0.14811240358401379, 0.11108430268801034, 0.11108430268801034, 0.061713501493339075, 0.13576970328534596, 0.628263265059174, 0.11634504908503222, 0.023269009817006445, 0.209421088353058, 0.10152932745114956, 0.20305865490229913, 0.3384310915038319, 0.16921554575191594, 0.16921554575191594, 0.195880414685176, 0.11193166553438628, 0.06995729095899143, 0.20987187287697429, 0.13991458191798287, 0.04197437457539486, 0.11193166553438628, 0.12592312372618458, 0.052322330367154904, 0.3139339822029294, 0.13080582591788725, 0.3662563125700843, 0.13080582591788725, 0.8156638901227733, 0.01812586422495052, 0.12688104957465363, 0.01812586422495052], \"Term\": [\"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"able\", \"able\", \"able\", \"able\", \"able\", \"able\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieving\", \"achieving\", \"achieving\", \"achieving\", \"addition\", \"addition\", \"addition\", \"addition\", \"addition\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"allows\", \"allows\", \"allows\", \"allows\", \"allows\", \"allows\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"application\", \"application\", \"application\", \"application\", \"application\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arbitrary\", \"arbitrary\", \"arbitrary\", \"arbitrary\", \"arbitrary\", \"arbitrary\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"artificial\", \"artificial\", \"artificial\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"audio\", \"audio\", \"audio\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"benchmarks\", \"benchmarks\", \"benchmarks\", \"benchmarks\", \"benchmarks\", \"benchmarks\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"beyond\", \"beyond\", \"beyond\", \"beyond\", \"beyond\", \"beyond\", \"capabilities\", \"capabilities\", \"capabilities\", \"capabilities\", \"capabilities\", \"capabilities\", \"capabilities\", \"cases\", \"cases\", \"cases\", \"cases\", \"cases\", \"cases\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computer\", \"computer\", \"computer\", \"computer\", \"conditional\", \"conditional\", \"conditional\", \"conditional\", \"conditional\", \"consists\", \"consists\", \"consists\", \"consists\", \"consists\", \"consists\", \"consists\", \"content\", \"content\", \"content\", \"content\", \"content\", \"context\", \"context\", \"context\", \"context\", \"control\", \"control\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrated\", \"demonstrated\", \"demonstrated\", \"demonstrated\", \"descent\", \"descent\", \"descent\", \"described\", \"described\", \"described\", \"described\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"developed\", \"developed\", \"developed\", \"developed\", \"developed\", \"developed\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"diffusion\", \"diffusion\", \"diffusion\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domains\", \"domains\", \"domains\", \"domains\", \"downstream\", \"downstream\", \"downstream\", \"downstream\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluate\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"examples\", \"examples\", \"examples\", \"examples\", \"examples\", \"examples\", \"examples\", \"extensive\", \"extensive\", \"extensive\", \"extensive\", \"extensive\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"fidelity\", \"fidelity\", \"finally\", \"finally\", \"finally\", \"finally\", \"finally\", \"finally\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"fixed\", \"fixed\", \"fixed\", \"fixed\", \"fixed\", \"fixed\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"furthermore\", \"furthermore\", \"furthermore\", \"furthermore\", \"furthermore\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalize\", \"generalize\", \"generalize\", \"generalize\", \"generalize\", \"generate\", \"generate\", \"generate\", \"generate\", \"generate\", \"generated\", \"generated\", \"generated\", \"generated\", \"generated\", \"generates\", \"generates\", \"generates\", \"generates\", \"generates\", \"generation\", \"generation\", \"generation\", \"generation\", \"generation\", \"generation\", \"generation\", \"generative\", \"generative\", \"generative\", \"generative\", \"generative\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imagenet\", \"imagenet\", \"imagenet\", \"imagenet\", \"imagenet\", \"images\", \"images\", \"images\", \"images\", \"images\", \"improved\", \"improved\", \"improved\", \"improved\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"improving\", \"improving\", \"improving\", \"improving\", \"increasing\", \"increasing\", \"increasing\", \"increasing\", \"increasing\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"inputs\", \"inputs\", \"inputs\", \"inputs\", \"inputs\", \"inputs\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"latent\", \"latent\", \"latent\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layers\", \"layers\", \"layers\", \"layers\", \"layers\", \"layers\", \"layers\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learns\", \"learns\", \"learns\", \"learns\", \"learns\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"limited\", \"limited\", \"limited\", \"limited\", \"limited\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"llms\", \"llms\", \"llms\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objects\", \"objects\", \"objects\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperforms\", \"outperforms\", \"outperforms\", \"outperforms\", \"outperforms\", \"outperforms\", \"outperforms\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"particular\", \"particular\", \"particular\", \"particular\", \"particular\", \"particular\", \"particular\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performing\", \"performing\", \"performing\", \"performing\", \"performing\", \"performing\", \"performing\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"powerful\", \"powerful\", \"powerful\", \"powerful\", \"powerful\", \"powerful\", \"powerful\", \"powerful\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"pretrained\", \"pretrained\", \"pretrained\", \"pretrained\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problems\", \"problems\", \"problems\", \"problems\", \"problems\", \"problems\", \"problems\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"properties\", \"properties\", \"properties\", \"properties\", \"properties\", \"properties\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"random\", \"random\", \"random\", \"random\", \"random\", \"range\", \"range\", \"range\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"reasoning\", \"reasoning\", \"reasoning\", \"reasoning\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"reducing\", \"reducing\", \"reducing\", \"reducing\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"remarkable\", \"remarkable\", \"remarkable\", \"remarkable\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"requires\", \"requires\", \"requires\", \"requires\", \"requires\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"samples\", \"samples\", \"samples\", \"samples\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scaling\", \"scaling\", \"scaling\", \"scaling\", \"scaling\", \"second\", \"second\", \"second\", \"second\", \"second\", \"self\", \"self\", \"self\", \"self\", \"self\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequences\", \"sequences\", \"sequences\", \"sequences\", \"sequences\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shot\", \"shot\", \"shot\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"since\", \"since\", \"since\", \"since\", \"since\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"solve\", \"solve\", \"solve\", \"solve\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"specifically\", \"specifically\", \"specifically\", \"specifically\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speed\", \"speed\", \"speed\", \"speed\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"steps\", \"steps\", \"steps\", \"steps\", \"steps\", \"steps\", \"steps\", \"still\", \"still\", \"still\", \"still\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"strong\", \"strong\", \"strong\", \"strong\", \"strong\", \"structure\", \"structure\", \"structure\", \"structure\", \"superior\", \"superior\", \"superior\", \"superior\", \"superior\", \"supervised\", \"supervised\", \"supervised\", \"supervised\", \"synthesis\", \"synthesis\", \"synthesis\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"tasks\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"term\", \"term\", \"term\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"thus\", \"thus\", \"thus\", \"thus\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transformers\", \"transformers\", \"transformers\", \"transformers\", \"transformers\", \"translation\", \"translation\", \"translation\", \"translation\", \"translation\", \"tuned\", \"tuned\", \"tuned\", \"tuned\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"understanding\", \"understanding\", \"understanding\", \"understanding\", \"understanding\", \"understanding\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"uses\", \"uses\", \"uses\", \"uses\", \"uses\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"various\", \"various\", \"various\", \"various\", \"various\", \"various\", \"various\", \"various\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"weights\", \"weights\", \"weights\", \"weights\", \"weights\", \"weights\", \"weights\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wide\", \"wide\", \"wide\", \"wide\", \"wide\", \"wide\", \"wide\", \"wide\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"word\", \"word\", \"word\", \"word\", \"words\", \"words\", \"words\", \"words\", \"words\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"zero\", \"zero\", \"zero\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el39301151405623904427042435276423\", ldavis_el39301151405623904427042435276423_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el39301151405623904427042435276423\", ldavis_el39301151405623904427042435276423_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el39301151405623904427042435276423\", ldavis_el39301151405623904427042435276423_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.098551 -0.105772       1        1  18.336973\n",
       "1     -0.067839 -0.114748       2        1   6.341712\n",
       "2     -0.147026  0.107536       3        1  10.334611\n",
       "3      0.126072  0.085102       4        1   5.069744\n",
       "4      0.047160  0.050081       5        1  11.243217\n",
       "5     -0.059314  0.043182       6        1  11.458790\n",
       "6      0.136759 -0.103031       7        1  13.098850\n",
       "7      0.030879  0.037289       8        1   5.826636\n",
       "8      0.031859  0.000360       9        1  18.289468, topic_info=            Term        Freq       Total Category  logprob  loglift\n",
       "259         text  164.000000  164.000000  Default  30.0000  30.0000\n",
       "72      language  258.000000  258.000000  Default  29.0000  29.0000\n",
       "253        image  219.000000  219.000000  Default  28.0000  28.0000\n",
       "262       speech  119.000000  119.000000  Default  27.0000  27.0000\n",
       "337    diffusion   86.000000   86.000000  Default  26.0000  26.0000\n",
       "..           ...         ...         ...      ...      ...      ...\n",
       "155         time   24.422032   95.843751   Topic9  -4.7819   0.3316\n",
       "129  performance   30.758383  194.010516   Topic9  -4.5512  -0.1429\n",
       "253        image   31.856975  219.794017   Topic9  -4.5161  -0.2326\n",
       "38         large   30.565356  196.645981   Topic9  -4.5575  -0.1627\n",
       "87         using   26.943085  160.287067   Topic9  -4.6836  -0.0844\n",
       "\n",
       "[452 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "0         1  0.200262  ability\n",
       "0         2  0.066754  ability\n",
       "0         3  0.300393  ability\n",
       "0         8  0.033377  ability\n",
       "0         9  0.367146  ability\n",
       "...     ...       ...      ...\n",
       "88        8  0.130806    world\n",
       "339       1  0.815664     zero\n",
       "339       2  0.018126     zero\n",
       "339       3  0.126881     zero\n",
       "339       9  0.018126     zero\n",
       "\n",
       "[1653 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook();\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False);\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(7, 0.9788595)],\n",
       " [(0, [7]),\n",
       "  (1, [7]),\n",
       "  (2, [7]),\n",
       "  (3, [7]),\n",
       "  (4, [7]),\n",
       "  (5, [7]),\n",
       "  (6, [7]),\n",
       "  (7, [7]),\n",
       "  (8, [7]),\n",
       "  (9, [7]),\n",
       "  (10, [7]),\n",
       "  (11, [7]),\n",
       "  (12, [7]),\n",
       "  (13, [7]),\n",
       "  (14, [7]),\n",
       "  (15, [7])],\n",
       " [(0, [(7, 0.99987495)]),\n",
       "  (1, [(7, 0.99985445)]),\n",
       "  (2, [(7, 0.9998665)]),\n",
       "  (3, [(7, 1.9999752)]),\n",
       "  (4, [(7, 0.9999338)]),\n",
       "  (5, [(7, 0.9999832)]),\n",
       "  (6, [(7, 1.9999878)]),\n",
       "  (7, [(7, 0.9998771)]),\n",
       "  (8, [(7, 0.9999957)]),\n",
       "  (9, [(7, 2.9999473)]),\n",
       "  (10, [(7, 0.9998533)]),\n",
       "  (11, [(7, 0.9999583)]),\n",
       "  (12, [(7, 0.99990034)]),\n",
       "  (13, [(7, 1.9999676)]),\n",
       "  (14, [(7, 2.9999454)]),\n",
       "  (15, [(7, 0.9999014)])])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lda[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- TOPIC 0 ---\n",
      "Keywords: 0.060*\"language\" + 0.031*\"tasks\" + 0.030*\"training\" + 0.026*\"large\" + 0.026*\"performance\" + 0.018*\"tuning\" + 0.017*\"fine\" + 0.016*\"shot\" + 0.016*\"data\" + 0.015*\"zero\"\n",
      "\n",
      "Representative Papers:\n",
      "- palm scaling language modeling with pathways (by aakanksha chowdhery et al, 2022) [Prob: 0.995]\n",
      "- large language models encode clinical knowledge (by singhal et al, 2022) [Prob: 0.994]\n",
      "- multitask prompted training enables zero shot task generalization (by victor sanh et al, 2022) [Prob: 0.993]\n",
      "- qlora efficient finetuning of quantized llms (by tim dettmers et al, 2023) [Prob: 0.993]\n",
      "- efficient streaming language models with attention sinks (by guangxuan xiao et al, 2023) [Prob: 0.992]\n",
      "\n",
      "\n",
      "--- TOPIC 1 ---\n",
      "Keywords: 0.039*\"language\" + 0.030*\"tasks\" + 0.027*\"word\" + 0.024*\"large\" + 0.022*\"code\" + 0.020*\"context\" + 0.015*\"method\" + 0.015*\"performance\" + 0.014*\"knowledge\" + 0.014*\"show\"\n",
      "\n",
      "Representative Papers:\n",
      "- do as i can not as i say grounding language in robotic affordances (by michael ahn et al, 2022) [Prob: 0.993]\n",
      "- neural word embedding as implicit matrix factorization (by omer levy and yoav goldberg, 2014) [Prob: 0.993]\n",
      "- tree of thoughts deliberate problem solving with large language models (by yao fu et al, 2023) [Prob: 0.991]\n",
      "- grounding large language models in interactive environments with online rl glam (by thomas carta et al, 2023) [Prob: 0.989]\n",
      "- a stochastic approximation method (by h robbins and s monro, 1951) [Prob: 0.834]\n",
      "\n",
      "\n",
      "--- TOPIC 2 ---\n",
      "Keywords: 0.081*\"text\" + 0.048*\"image\" + 0.034*\"audio\" + 0.032*\"speech\" + 0.025*\"generation\" + 0.021*\"translation\" + 0.020*\"diffusion\" + 0.014*\"synthesis\" + 0.013*\"high\" + 0.013*\"quality\"\n",
      "\n",
      "Representative Papers:\n",
      "- audiogen textually guided audio generation (by felix kreuk et al, 2022) [Prob: 0.994]\n",
      "- make a video text to video generation without text video data (by uriel singer et al, 2022) [Prob: 0.993]\n",
      "- audioldm text to audio generation with latent diffusion models (by haohe liu et al, 2023) [Prob: 0.992]\n",
      "- scaling up gans for text to image synthesis gigagan (by minguk kang et al, 2023) [Prob: 0.991]\n",
      "- hierarchical text conditional image generation with clip latents dall e 2 (by aditya ramesh et al, 2022) [Prob: 0.990]\n",
      "\n",
      "\n",
      "--- TOPIC 3 ---\n",
      "Keywords: 0.040*\"optimization\" + 0.031*\"machine\" + 0.026*\"performance\" + 0.025*\"algorithm\" + 0.023*\"show\" + 0.022*\"translation\" + 0.020*\"learning\" + 0.018*\"convolutional\" + 0.017*\"process\" + 0.016*\"problems\"\n",
      "\n",
      "Representative Papers:\n",
      "- fully convolutional networks for semantic segmentation (by j long et al, 2015) [Prob: 0.990]\n",
      "- predictive business process monitoring with lstm neural networks (by tax n et al, 2017) [Prob: 0.990]\n",
      "- on the properties of neural machine translation encoder decoder approaches (by kyunghyun cho et al, 2014) [Prob: 0.990]\n",
      "- learning phrase representations using rnn encoder decoder for statistical machine translation (by cho k et al, 2014) [Prob: 0.990]\n",
      "- hyperband a novel bandit based approach to hyperparameter optimization (by lisha li et al, 2016) [Prob: 0.987]\n",
      "\n",
      "\n",
      "--- TOPIC 4 ---\n",
      "Keywords: 0.048*\"learning\" + 0.029*\"detection\" + 0.025*\"time\" + 0.020*\"object\" + 0.019*\"real\" + 0.018*\"human\" + 0.017*\"reinforcement\" + 0.017*\"high\" + 0.016*\"approach\" + 0.016*\"using\"\n",
      "\n",
      "Representative Papers:\n",
      "- human level control through deep reinforcement learning (by volodymyr mnih et al, 2015) [Prob: 0.995]\n",
      "- mastering diverse domains through world models dreamerv3 (by danijar hafner et al, 2023) [Prob: 0.993]\n",
      "- 3d gaussian splatting for real time radiance field rendering (by bernhard kerbl et al, 2023) [Prob: 0.993]\n",
      "- magnetic control of tokamak plasmas through deep reinforcement learning (by jonas degrave et al, 2022) [Prob: 0.992]\n",
      "- you only look once unified real time object detection (by j redmon et al, 2016) [Prob: 0.992]\n",
      "\n",
      "\n",
      "--- TOPIC 5 ---\n",
      "Keywords: 0.046*\"image\" + 0.029*\"diffusion\" + 0.026*\"images\" + 0.022*\"speech\" + 0.020*\"data\" + 0.020*\"training\" + 0.017*\"high\" + 0.015*\"resolution\" + 0.014*\"large\" + 0.013*\"dataset\"\n",
      "\n",
      "Representative Papers:\n",
      "- on distillation of guided diffusion models (by chenlin meng et al, 2022) [Prob: 0.995]\n",
      "- wavlm large scale self supervised pre training for full stack speech processing (by sanyuan chen et al, 2022) [Prob: 0.993]\n",
      "- structure and content guided video synthesis with diffusion models gen 1 (by omer bar tal et al, 2023) [Prob: 0.992]\n",
      "- synthetic data from diffusion models improves imagenet classification (by shekoofeh azizi et al, 2023) [Prob: 0.991]\n",
      "- image super resolution using deep convolutional networks (by c dong et al, 2016) [Prob: 0.991]\n",
      "\n",
      "\n",
      "--- TOPIC 6 ---\n",
      "Keywords: 0.033*\"training\" + 0.027*\"deep\" + 0.025*\"learning\" + 0.024*\"error\" + 0.022*\"data\" + 0.017*\"generalization\" + 0.016*\"function\" + 0.016*\"parameters\" + 0.015*\"accuracy\" + 0.015*\"random\"\n",
      "\n",
      "Representative Papers:\n",
      "- the generalization error of random features regression precise asymptotics and double descent curve (by song mei and andrea montanari, 2020) [Prob: 0.994]\n",
      "- a farewell to the bias variance tradeoff an overview of the theory of overparameterized machine learning (by yehuda dar et al, 2021) [Prob: 0.992]\n",
      "- dropout as a bayesian approximation representing model uncertainty in deep learning (by yarin gal and zoubin ghahramani, 2015) [Prob: 0.991]\n",
      "- batch normalization accelerating deep network training by reducing internal covariate shift (by sergey ioffe and christian szegedy, 2015) [Prob: 0.991]\n",
      "- the neural tangent kernel in high dimensions triple descent and a multi scale theory of generalization (by ben adlam and jeffrey pennington, 2020) [Prob: 0.990]\n",
      "\n",
      "\n",
      "--- TOPIC 7 ---\n",
      "Keywords: 0.035*\"visual\" + 0.032*\"gradient\" + 0.029*\"methods\" + 0.022*\"learning\" + 0.021*\"stochastic\" + 0.017*\"self\" + 0.016*\"system\" + 0.016*\"based\" + 0.015*\"supervised\" + 0.015*\"propose\"\n",
      "\n",
      "Representative Papers:\n",
      "- visual chatgpt talking drawing and editing with visual foundation models (by chenfei wu et al, 2023) [Prob: 0.992]\n",
      "- vision transformers need registers (by t darcet el al, 2023) [Prob: 0.989]\n",
      "- optimizing neural networks with kronecker factored approximate curvature (by james martens and roger grosse, 2015) [Prob: 0.989]\n",
      "- auto encoding variational bayes (by diederik p kingma and max welling, 2013) [Prob: 0.986]\n",
      "- tracking emerges by colorizing videos (by carl vondrick et al, 2018) [Prob: 0.982]\n",
      "\n",
      "\n",
      "--- TOPIC 8 ---\n",
      "Keywords: 0.025*\"recurrent\" + 0.023*\"recognition\" + 0.022*\"deep\" + 0.019*\"based\" + 0.018*\"tasks\" + 0.018*\"data\" + 0.018*\"learning\" + 0.016*\"results\" + 0.016*\"long\" + 0.016*\"convolutional\"\n",
      "\n",
      "Representative Papers:\n",
      "- cnn features off the shelf an astounding baseline for recognition (by a razavian et al, 2014) [Prob: 0.994]\n",
      "- independently recurrent neural network indrnn building a longer and deeper rnn (by li s et al, 2018) [Prob: 0.994]\n",
      "- decaf a deep convolutional activation feature for generic visual recognition (by j donahue et al, 2014) [Prob: 0.993]\n",
      "- return of the devil in the details delving deep into convolutional nets (by k chatfield et al, 2014) [Prob: 0.993]\n",
      "- speech recognition with deep recurrent neural networks (by graves a mohamed a hinton g e, 2013) [Prob: 0.992]\n"
     ]
    }
   ],
   "source": [
    "def dominant_topic(doc_num):\n",
    "    bow = corpus[doc_num]\n",
    "    topics = sorted(lda[bow][0], key=lambda x: x[1], reverse=True)\n",
    "    return topics[0] if topics else (0, 0)\n",
    "\n",
    "meta['dominant_topic'] = [dominant_topic(i)[0] for i in range(len(meta))]\n",
    "meta['topic_probability'] = [dominant_topic(i)[1] for i in range(len(meta))]\n",
    "\n",
    "# Get representative papers for each topic\n",
    "def get_representative_papers(topic_id, n_samples=5):\n",
    "    # Filter papers where this is the dominant topic\n",
    "    topic_papers = meta[meta['dominant_topic'] == topic_id]\n",
    "    # Sort by probability (most representative first)\n",
    "    topic_papers = topic_papers.sort_values('topic_probability', ascending=False)\n",
    "    # Return top n samples\n",
    "    return topic_papers.head(n_samples)[['title', 'authors', 'year', 'topic_probability']]\n",
    "\n",
    "for topic_id in range(num_topics):\n",
    "    print(f\"\\n\\n--- TOPIC {topic_id} ---\")\n",
    "    # Get the topic keywords\n",
    "    print(\"Keywords:\", lda.print_topic(topic_id))\n",
    "    print(\"\\nRepresentative Papers:\")\n",
    "    sample_papers = get_representative_papers(topic_id)\n",
    "    # Check if we have any papers for this topic\n",
    "    if len(sample_papers) > 0:\n",
    "        for idx, row in sample_papers.iterrows():\n",
    "            print(f\"- {row['title']} (by {row['authors']}, {row['year']}) [Prob: {row['topic_probability']:.3f}]\")\n",
    "    else:\n",
    "        print(\"No papers found with this as dominant topic.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
