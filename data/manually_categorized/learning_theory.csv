year,title,authors,link
1989,Learnability and the Vapnik-Chervonenkis Dimension,Blumer et al.,https://dl.acm.org/doi/10.1145/76359.76371
1989,Multilayer Feedforward Networks are Universal Approximators,Hornik et al.,https://www.sciencedirect.com/science/article/abs/pii/0893608089900208
1991,Approximation capabilities of multilayer feedforward networks,Kurt Hornik,https://www.sciencedirect.com/science/article/abs/pii/089360809190009T
1992,Principles of Risk Minimization for Learning Theory,V. Vapnik,https://proceedings.neurips.cc/paper/1991/file/ff4d5fbbafdf976cfdc032e3bde78de5-Paper.pdf
1993,Multilayer Feedforward Networks With a Nonpolynomial Activation Function Can Approximate Any Function,Moshe Leshno et al.,https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315
1997,No Free Lunch Theorems for Optimization,David H. Wolpert and William G. Macready,https://ieeexplore.ieee.org/document/585893
1997,Computational Power of Neural Networks: A Characterization in Terms of Kolmogorov Complexity,José L. Balcázar et al.,The computational power of recurrent neural networks is shown to depend ultimately on the complexity of the real constants (weights) of the network. The complexity  or information contents  of the weights is measured by a variant of resource-bounded Kolmogorov (1965) complexity  taking into account the time required for constructing the numbers. In particular  we reveal a full and proper hierarchy of nonuniform complexity classes associated with networks having weights of increasing Kolmogorov complexity
1999,Generalization in a linear perceptron in the presence of noise,Anders Krogh and John A Hertz,The authors study the evolution of the generalization ability of a simple linear perceptron with N inputs which learns to imitate a 'teacher perceptron'. The system is trained on p= alpha N example inputs drawn from some distribution and the generalization ability is measured by the average agreement with the teacher on test examples drawn from the same distribution. The dynamics may be solved analytically and exhibits a phase transition from imperfect to perfect generalization at alpha =1  when there are no errors (static noise) in the training examples. If the examples are produced by an erroneous teacher  overfitting is observed  i.e. the generalization error starts to increase after a finite time of training. It is shown that a weight decay of the same size as the variance of the noise (errors) on the teacher improves on the generalization and suppresses the overfitting. The generalization error as a function of time is calculated numerically for various values of the parameters. Finally dynamic noise in the training is considered. White noise on the input corresponds on average to a weight decay  and can thus improve generalization  whereas white noise on the weights or the output degrades generalization. Generalization is particularly sensitive to noise on the weights (for alpha (1) where it makes the error constantly increase with time  but this effect is also shown to be damped by a weight decay. Weight noise and output noise acts similarly above the transition at alpha =1.
2014,Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images,Anh Nguyen et al.,https://arxiv.org/pdf/1412.1897.pdf
2015,Deep Learning and the Information Bottleneck Principle,Naftali Tishby and Noga Zaslavsky,https://arxiv.org/abs/1503.02406
2016,Understanding deep learning requires rethinking generalization,Chiyuan Zhang et al.,https://arxiv.org/pdf/1611.03530.pdf
2017,On Calibration of Modern Neural Networks,Chuan Guo et al.,http://proceedings.mlr.press/v70/guo17a.html
2017,GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium,Martin Heusel et al.,https://arxiv.org/abs/1706.08500v6
2018,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,Arthur Jacot et al.,https://arxiv.org/abs/1806.07572
2018,"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks",Jonathan Frankle and Michael Carbin,https://arxiv.org/abs/1803.03635
2018,"Relational inductive biases, deep learning, and graph networks",Peter W. Battaglia et al.,https://arxiv.org/pdf/1806.01261.pdf
2018,A Spline Theory of Deep Networks,Randall Balestriero and Richard G. Baraniuk,https://proceedings.mlr.press/v80/balestriero18b.html
2019,Deep Double Descent: Where Bigger Models and More Data Hurt,Preetum Nakkiran et al.,https://arxiv.org/abs/1912.02292
2019,On the covariance-Hessian relation in evolution strategies,Ofer M. Shir and Amir Yehudayoff,https://arxiv.org/abs/1806.03674
2019,On the Measure of Intelligence,François Chollet,https://arxiv.org/abs/1911.01547
2020,The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization,Ben Adlam and Jeffrey Pennington,https://arxiv.org/abs/2008.06786
2020,Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning,Armen Aghajanyan et al.,https://arxiv.org/abs/2012.13255
2021,Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets,Alethea Power et al.,https://arxiv.org/abs/2201.02177
2021,Learning in High Dimension Always Amounts to Extrapolation,Randall Balestriero et al.,https://arxiv.org/pdf/2110.09485.pdf
2022,Towards Understanding Grokking: An Effective Theory of Representation Learning,Ziming Liu et al.,https://arxiv.org/abs/2205.10343
